# 2025-12-22
https://papers.cool/arxiv/cs.IR?date=2025-12-22

## 1. [R1] 通过因果消除共同购买关系和反事实暴露来推荐多样性

https://papers.cool/arxiv/2512.17733


Authors: Jingmao Zhang, Zhiting Zhao, Yunqi Lin, Jianghong Ma, Tianjun Wei, Haijun Zhang, Xiaofeng Zhang


Summary: 除了用户-项目建模外，项目间关系也越来越多地被用来提升推荐。然而，常见方法主要依赖共现，容易受到项目流行度偏差和用户属性的影响，从而降低嵌入的质量和性能。与此同时，尽管多样性被公认为推荐质量的关键方面，现有研究对此关注有限，缺乏因果视角和理论基础。为应对这些挑战，我们提出了“Cadence：通过因果解混淆共同购买关系和反事实暴露的多样性推荐”——这是一个以LightGCN为骨干的即插即用框架，主要旨在增强推荐多样性同时保持准确性。首先，我们计算了项目间的无偏非对称共购关系（UACR），不包括商品受欢迎度和用户属性，构建了一个去纠缠的有向项目图，并通过聚合机制细化嵌入。其次，我们利用UACR识别与用户互动项目具有强烈因果关系但尚未被接触的多样化类别。随后，我们模拟它们在高曝光场景下的行为，从而显著增强推荐多样性，同时保持相关性。在真实世界数据集上的大量实验表明，我们的方法在多样性和准确性方面始终优于最先进的多样性模型，并进一步验证了其在基线上的有效性、可转移性和效率。

## 2. [R2] 更低成本保温：Pinterest冷启动推荐的经济高效策略

https://papers.cool/arxiv/2512.17277

Authors: Saeed Ebrahimi, Weijie Jiang, Jaewon Yang, Olafur Gudmundsson, Yucheng Tu, Huizhong Duan

Summary: Pinterest 是一个领先的视觉发现平台，推荐系统（RecSys）是向用户提供相关、引人入胜且新鲜内容的关键。本文研究了改进冷启动（CS）项目预测RecSys模型的问题，这些项目在训练数据中出现频率较低。尽管学术界对这一问题有深入研究，但在像Pinterest这样的平台规模上，很少有研究有效解决其根源。通过对实时交通数据的研究，我们识别出计算机科学问题的若干挑战，并为每个挑战制定了相应的解决方案：首先，工业规模的RecSys模型必须在严格的计算约束下运行。由于计算机科学项目属于少数，任何相关改进都必须高度成本效益。为此，我们的解决方案设计得轻量化，总参数仅增加5%。其次，CS项目仅由非历史特征（如内容或属性）表示，模型通常将其视为次要。为了提升它们的重要性，我们引入了非历史特征的残留联系。第三，CS题目通常获得较低的预测分数，降低了被曝光的可能性。我们通过在模型中加入一个分数正则化项来缓解这一问题。第四，与计算机科学项目相关的标签稀疏，使模型难以从中学习。我们应用流形混合技术来解决这种数据稀疏性。我们共同实施的方法使Pinterest的新鲜内容互动率提高了10%，同时未对整体互动和成本产生负面影响，并已部署服务于超过5.7亿Pinterest用户。

# 2025-12-23
https://papers.cool/arxiv/cs.IR?date=2025-12-23

无


# 2025-12-24
https://papers.cool/arxiv/cs.IR?date=2025-12-24

## 3. [R1] 预训练基础模型的检索增强提示学习

https://papers.cool/arxiv/2512.20145


Authors: Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang


Summary: 预训练基础模型（PFM）已成为促进大规模多模态学习的关键。研究人员通过提示学习有效地运用了“预训练、提示和预测”范式，从而提升了少数机会的表现。然而，PFM的提示学习方法仍然遵循参数学习范式。因此，记忆和死记硬背中泛化的稳定性可能会受到影响。更具体地说，传统的提示学习在充分利用非典型实例和避免在完全监督训练过程中对浅层模式进行有限数据时可能面临困难。为克服这些限制，我们提出了名为RetroPrompt的方法，旨在通过将知识与单纯记忆分离，实现记忆与泛化之间的平衡。与传统提示方法不同，RetroPrompt 利用由训练数据生成的公开知识库，并在输入、训练和推理阶段整合检索机制。这使得模型能够主动从语料库中获取相关的上下文信息，从而增强可用的线索。我们在自然语言处理和计算机视觉任务的多种数据集上进行了全面实验，以展示我们提出的方法RetroPrompt在零样本和少数样本场景中的优异表现。通过对记忆模式的详细分析，我们观察到RetroPrompt有效减少了对死记硬背的依赖，从而增强了泛化能力。

# 2025-12-25
https://papers.cool/arxiv/cs.IR?date=2025-12-25

无