# 2025-12-15
https://papers.cool/arxiv/cs.IR?date=2025-12-15&show=50

## 1. [R3] 公平：集中注意力就是生成性推荐所需要的全部

https://papers.cool/arxiv/2512.11254


Authors: Longtao Xiao, Haolin Zhang, Guohao Cai, Jieming Zhu, Yifan Wang, Heng Chang, Zhenhua Dong, Xiu Li, Ruixuan Li


Summary: 近年来，基于变压器的生成推荐在用户行为建模方面引起了广泛关注。然而，它通常需要将项目离散化为多代码表示（例如，通常四个代码标记或更多），这会大幅增加原始项目序列的长度。这一扩展对基于变压器建模具有固有噪声的用户行为序列带来了挑战，因为它们往往过度关注无关或噪声的上下文。为缓解这一问题，我们提出了FAIR，这是首个具有聚焦关注的生成式推荐框架，能够将注意力分数提升到相关情境，同时抑制对无关情境的注意力评分。具体来说，我们提出：（1）一种集成在标准Transformer中的专注注意力机制，该机制学习两组独立的Q和K注意力权重，并计算它们的差异作为最终注意力分数，以消除注意力噪声，同时专注于相关情境;（2）噪声鲁棒性目标，鼓励模型在随机扰动下保持稳定的注意力模式，防止因噪声导致不希望的无关情境转变;以及（3）互信息最大化目标，指导模型识别对下一条预测最有用的上下文。我们在四项公开基准测试上验证了FAIR的有效性，证明其优于现有方法的性能。