# 2025-12-29
https://papers.cool/arxiv/cs.IR?date=2025-12-29

无

# 2025-12-30
https://papers.cool/arxiv/cs.IR?date=2025-12-30
## 1. [R1] OxygenREC：一个基于指令的生成式电子商务推荐框架

https://papers.cool/arxiv/2512.22386


Authors: Xuegang Hao, Ming Zhang, Alex Li, Xiangyu Qian, Zhi Ma, Yanlong Zang, Shijie Yang, Zhongxuan Han, Xiaolong Ma, Jinguang Liu, Zhen Li, Zhida Jiang, Shusheng Wang, Ning Tang, Yanchen Qiao, Chenxiang Yang, Chen Sun, Jincheng Yuan, Chunhua Peng, Heng Hu, Peijun Yang, Baopeng Yuan, Caiyun Qiu, Zhaolong Xing, Haofei Yuan, Haipeng Zhang, Yuzhang Guo, Weijie Ding, Jiahua Gao, Hao Huang, Zhen Chen, Tongxuan Liu, Pinghua Gong


Summary: 传统推荐系统在多阶段优化目标上存在不一致性的问题。生成式推荐（GR）通过端到端框架来缓解这些问题;然而，现有方法仍然依赖基于归纳模式的匹配机制。虽然响应迅速，但它们缺乏揭示复杂用户意图的能力，这些意图需要基于世界知识进行演绎推理。与此同时，LLM展现出强大的深度推理能力，但其延迟和计算成本对工业应用来说依然具有挑战性。更关键的是，多场景可扩展性存在性能瓶颈：如图1所示，现有解决方案需要为每个场景独立培训和部署，导致资源利用率低且维护成本高——这是广义相对论文献中未涉及的挑战。为此，我们介绍了OxygenREC这一工业推荐系统，利用快慢思维实现深度推理，同时具备严格的延迟和多场景的真实环境需求。首先，我们采用快速-慢思考架构。慢思考使用近线大型语言模型流水线来综合上下文推理指令，而快速思维则采用高效编码-解码骨干来实现实时生成。其次，为确保推理指令有效提升推荐生成，我们引入了与指令引导检索（IGR）的语义对齐机制，以过滤与意图相关的历史行为，并利用查询到项目（Q2I）损失以实现指令与项目的一致性。最后，为了解决多场景可扩展性问题，我们将场景信息转化为可控指令，采用统一奖励映射和软自适应组剪辑策略优化（SA-GCPO），使策略与多样化业务目标保持一致，实现“一次部署”的模式。