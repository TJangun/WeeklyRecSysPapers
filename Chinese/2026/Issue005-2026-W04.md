# 2026-01-19
https://papers.cool/arxiv/cs.IR?date=2026-01-19

## 1. [R1] 长尾顺序推荐的尾部感知数据增强

https://papers.cool/arxiv/2601.10933


Authors: Yizhou Dang, Zhifu Wei, Minhan Huang, Lianbo Ma, Jianzhe Zhao, Guibing Guo, Xingwei Wang


Summary: 顺序推荐（SR）基于用户的历史交互序列学习偏好，并提供个性化建议。在现实场景中，大多数用户只能与少数物品互动，而大多数物品很少被消费。这种普遍存在的长尾挑战限制了模型学习用户偏好的能力。尽管此前曾努力通过从头部部件丰富尾部物品/使用者的知识，或通过额外的上下文信息提升尾部学习，但它们仍面临以下问题：1）难以改善尾部用户/物品交互稀少的情况，导致尾部部分偏好学习不完整。2）现有方法常常在提升尾部用户/物品准确性时降低整体或头部部件性能，从而损害用户体验。我们提出了尾部感知数据增强（TADA）用于长尾顺序推荐，该方法在保持头部表现的同时提升尾部物品/用户的交互频率，从而促进模型对尾部的学习能力。具体来说，我们首先通过线性模型捕捉低受欢迎度项目之间的共现和相关性。基于此，我们设计了两个尾部感知增强作符，分别是T-Substitute和T-Insert。前者用相关词替换主词项，而后者则利用共现关系，通过包含头项和尾项来扩展原始序列。增强序列和原始序列在表示层面被混合，以保持偏好知识。我们进一步将混合作扩展到不同的尾用户序列和增强序列，以生成更丰富的增强样本，从而提升尾部性能。全面的实验证明了我们方法的优越性。代码在 https://github.com/KingGugu/TADA 提供。

## 2. [R1] EncodeRec：推荐系统嵌入骨干

https://papers.cool/arxiv/2601.10837


Authors: Guy Hadad, Neomi Rabaev, Bracha Shapira


Summary: 近期推荐系统越来越多地利用大型预训练语言模型（PLM）的嵌入。然而，这类嵌入存在两个关键局限：（1）PLM未明确优化以生成结构化且判别性的嵌入空间;（2）其表示过于泛化，常常未能捕捉推荐任务中关键的领域特异语义。我们介绍EncodeRec，一种旨在将文本表示与推荐目标对齐的方法，同时直接从题目描述中学习紧凑且信息丰富的嵌入。EncodeRec 在推荐器系统训练过程中保持语言模型参数冻结，使其计算效率高且不牺牲语义准确性。核心推荐基准测试的实验证明了其作为顺序推荐模型骨干和语义ID标记化的有效性，相较于基于PLM和嵌入模型基线的显著提升。这些结果强调了嵌入适应在弥合通用语言模型与实用推荐系统之间鸿沟的关键作用。

# 2026-01-21
https://papers.cool/arxiv/cs.IR?date=2026-01-21

## 3. [R2] HyFormer：重新探讨序列建模与特征相互作用在CTR预测中的作用

https://papers.cool/arxiv/2601.12681


Authors: Yunwen Huang, Shiyong Hong, Xijun Xiao, Jinqiu Jin, Xuanyuan Luo, Zhe Wang, Zheng Chai, Shikang Wu, Yuchao Zheng, Jingjian Lin

Summary: 工业大型推荐模型（LRM）面临在严格效率约束下联合建模长程用户行为序列和异质非顺序特征的挑战。然而，大多数现有架构采用解耦流水线：长序列先用基于查询令牌的序列压缩器（如 LONGER）压缩，然后通过像 RankMixer 这样的令牌混合模块与密集特征融合，从而限制了表示容量和交互灵活性。本文介绍了HyFormer，一种统一的混合变换器架构，将长序列建模和特征交互紧密集成为单一骨干。从序列建模的角度，我们重新审视并设计了LRM（逻辑模型）中的查询标记，并将LRM建模任务定位为一个交替优化过程，整合了两个核心组成部分：查询解码，将非顺序特征扩展为全局标记，并对长行为序列的逐层键值表示进行长序列解码;以及查询增强，通过高效的令牌混合增强跨查询和跨序列异构交互。这两种互补机制通过迭代方式进行，以优化跨层的语义表示。在数十亿级工业数据集上的广泛实验表明，在可比参数和FLOP预算下，HyForformer始终优于强劲的LONGER和RankMixer基线，同时在参数和FLOP增加时表现出更优越的扩展行为。在高流量生产系统中的大规模在线A/B测试进一步验证了其有效性，显示出相较于已部署的最先进模型有显著提升。这些结果凸显了HyForformer作为工业长程模型统一建模框架的实用性和可扩展性。

# 2026-01-22
https://papers.cool/arxiv/cs.IR?date=2026-01-22

## 4. [R2] 从洞察到干预：可解释的神经元引导，用于控制推荐系统中的受欢迎偏差

https://papers.cool/arxiv/2601.15122


Authors: Parviz Ahmadov, Masoud Mansoury


Summary: 人气偏见是推荐系统中普遍存在的挑战，少数热门商品占据关注度，而大多数不受欢迎的商品则曝光不足。这种不平衡会降低推荐质量，导致不公平的商品曝光。尽管现有的缓解方法在一定程度上解决了这一问题，但它们的运作往往缺乏透明度。本文提出了一种事后方法PopSteer，利用稀疏自编码器（SAE）来解释并减轻推荐模型中的受欢迎偏差。SAE经过训练，能够复制训练模型的行为，同时实现神经元层面的可解释性。通过引入对热门或不受欢迎物品有强烈偏好的合成用户，我们识别出通过激活模式编码受欢迎信号的神经元。然后，我们通过调整最有偏的神经元激活来引导推荐。在三个使用顺序推荐模型的公开数据集上的实验表明，PopSteer 在对准确性影响最小的情况下显著提升了公平性，同时提供了可解读的洞见和对公平性与准确性权衡的细致控制。

# 2026-01-23
https://papers.cool/arxiv/cs.IR?date=2026-01-23

## 5. [R1] 加强基于扩散的顺序推荐中缺失数据的指导

https://papers.cool/arxiv/2601.15673


Authors: Qilong Yan, Yifei Xing, Dugang Liu, Jingpu Duan, Jian Yin


Summary: 当代顺序推荐方法正变得更加复杂，从分类转向扩散引导的生成范式。然而，用户信息形式的指导质量常因观测序列中缺失的数据而受损，导致生成质量不理想。现有方法通过移除本地相似项目来解决这个问题，但忽略了用户兴趣中的“关键转折点”，而这些关键点对于准确预测后续用户意图至关重要。为此，我们提出了一种新的反事实注意力调节扩散模型（CARD），该模型侧重于放大关键兴趣转折点的信号，同时识别并抑制用户序列中的噪声。CARD包括（1）一种双侧汤普森采样方法，用于识别经历显著兴趣转移的序列，以及（2）用于量化每个条目重要性的反事实注意力机制。通过这种方式，CARD为扩散模型提供了由动态重新加权相互作用矢量组成的高质量引导信号，从而实现有效生成。实验表明，我们的方法在真实世界数据上运行良好，且计算成本高昂。我们的代码可在 https://github.com/yanqilong3321/CARD 获取。
