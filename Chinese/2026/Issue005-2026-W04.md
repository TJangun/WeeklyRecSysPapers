# 2026-01-19
https://papers.cool/arxiv/cs.IR?date=2026-01-19

## 1. [R1] 长尾顺序推荐的尾部感知数据增强

https://papers.cool/arxiv/2601.10933


Authors: Yizhou Dang, Zhifu Wei, Minhan Huang, Lianbo Ma, Jianzhe Zhao, Guibing Guo, Xingwei Wang


Summary: 顺序推荐（SR）基于用户的历史交互序列学习偏好，并提供个性化建议。在现实场景中，大多数用户只能与少数物品互动，而大多数物品很少被消费。这种普遍存在的长尾挑战限制了模型学习用户偏好的能力。尽管此前曾努力通过从头部部件丰富尾部物品/使用者的知识，或通过额外的上下文信息提升尾部学习，但它们仍面临以下问题：1）难以改善尾部用户/物品交互稀少的情况，导致尾部部分偏好学习不完整。2）现有方法常常在提升尾部用户/物品准确性时降低整体或头部部件性能，从而损害用户体验。我们提出了尾部感知数据增强（TADA）用于长尾顺序推荐，该方法在保持头部表现的同时提升尾部物品/用户的交互频率，从而促进模型对尾部的学习能力。具体来说，我们首先通过线性模型捕捉低受欢迎度项目之间的共现和相关性。基于此，我们设计了两个尾部感知增强作符，分别是T-Substitute和T-Insert。前者用相关词替换主词项，而后者则利用共现关系，通过包含头项和尾项来扩展原始序列。增强序列和原始序列在表示层面被混合，以保持偏好知识。我们进一步将混合作扩展到不同的尾用户序列和增强序列，以生成更丰富的增强样本，从而提升尾部性能。全面的实验证明了我们方法的优越性。代码在 https://github.com/KingGugu/TADA 提供。

## 2. [R1] EncodeRec：推荐系统嵌入骨干

https://papers.cool/arxiv/2601.10837


Authors: Guy Hadad, Neomi Rabaev, Bracha Shapira


Summary: 近期推荐系统越来越多地利用大型预训练语言模型（PLM）的嵌入。然而，这类嵌入存在两个关键局限：（1）PLM未明确优化以生成结构化且判别性的嵌入空间;（2）其表示过于泛化，常常未能捕捉推荐任务中关键的领域特异语义。我们介绍EncodeRec，一种旨在将文本表示与推荐目标对齐的方法，同时直接从题目描述中学习紧凑且信息丰富的嵌入。EncodeRec 在推荐器系统训练过程中保持语言模型参数冻结，使其计算效率高且不牺牲语义准确性。核心推荐基准测试的实验证明了其作为顺序推荐模型骨干和语义ID标记化的有效性，相较于基于PLM和嵌入模型基线的显著提升。这些结果强调了嵌入适应在弥合通用语言模型与实用推荐系统之间鸿沟的关键作用。