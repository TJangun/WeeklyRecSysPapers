# 2026-01-12
https://papers.cool/arxiv/cs.IR?date=2026-01-12&show=50

## 1. [R2] 自回归排名：弥合双编码器与交叉编码器之间的差距

https://papers.cool/arxiv/2601.05588

Authors: Benjamin Rozonoyer, Chong You, Michael Boratko, Himanshu Jain, Nilesh Gupta, Srinadh Bhojanapalli, Andrew McCallum, Felix Yu

Summary: 双编码器和交叉编码器长期以来一直是信息检索（IR）的主力，但正受到大型语言模型（LLM）新兴能力的挑战。基于LLM的方法称为点状生成排序——生成长度相当于单个docID的令牌，而非列表，以实现通过beam搜索进行排序——结合了效率和表达力的优势，同时利用了因果变换器的上下文功能。尽管有大量证据表明预训练的大型语言模型非常适合排名，但我们发现绝大多数基于LLM的方法依赖于下一标记预测，这是一种从根本上与排名无关的损失函数（尤其是在点级监督下）。本文首先证明了多令牌docID的点状生成排序表达力优于双编码器。随后，我们提出了SToICaL——一种简单的令牌-项目校准损失——可以在点化设置中，在项目和令牌层面都包含排名感知监督。我们运行一系列基于WordNet（Fellbaum， 1998）和ESCI（Reddy等，arXiv：2206.06588）的排序任务实验。SToICaL的两种变体成功抑制了无效docID生成的概率，并在常见排名指标上提升了超越前一检索的水平。

# 2026-01-13
https://papers.cool/arxiv/cs.IR?date=2026-01-13&show=50

## 2. [R3] GAP-Net：通过门控自适应渐进学习校准用户意图以实现点击率预测

https://papers.cool/arxiv/2601.07613

Authors: Ke Shenqiang, Wei Jianxiong, Hua Qingsong

Summary: 顺序用户行为建模对于点击率（CTR）预测至关重要，但却受到三个内在瓶颈的阻碍：（1）“注意力消耗”现象，即标准Softmax强制模型将概率质量分配给噪声行为;（2）静态查询假设，忽略了由实时上下文驱动的用户意图动态变化;以及（3）僵化视图聚合，无法根据决策上下文自适应地加权异构时间信号。为弥合这些空白，我们提出了GAP-Net（门控自适应渐进网络），这是一个统一框架，建立“三重门控”架构，逐步精炼从微观特征到宏观视角的信息。GAP-Net通过三种整合机制运行：（1）自适应稀疏门控注意力（ASGA）采用微观门控强制稀疏性，有效抑制大规模噪声激活;（2） 门控级联查询校准（GCQC）通过中层级级联通道，动态对齐实时触发器和长期记忆;以及（3）上下文门控去噪融合（CGDF）执行宏级调制，以协调多视图序列的聚合。工业数据集上的大量实验表明，GAP-Net相较于最先进的基线实现了显著改进，在对相互作用噪声和意图漂移方面表现出更优越的鲁棒性。