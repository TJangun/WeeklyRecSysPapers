# 2026-01-12
https://papers.cool/arxiv/cs.IR?date=2026-01-12&show=50

## 1. [R2] 自回归排名：弥合双编码器与交叉编码器之间的差距

https://papers.cool/arxiv/2601.05588

Authors: Benjamin Rozonoyer, Chong You, Michael Boratko, Himanshu Jain, Nilesh Gupta, Srinadh Bhojanapalli, Andrew McCallum, Felix Yu

Summary: 双编码器和交叉编码器长期以来一直是信息检索（IR）的主力，但正受到大型语言模型（LLM）新兴能力的挑战。基于LLM的方法称为点状生成排序——生成长度相当于单个docID的令牌，而非列表，以实现通过beam搜索进行排序——结合了效率和表达力的优势，同时利用了因果变换器的上下文功能。尽管有大量证据表明预训练的大型语言模型非常适合排名，但我们发现绝大多数基于LLM的方法依赖于下一标记预测，这是一种从根本上与排名无关的损失函数（尤其是在点级监督下）。本文首先证明了多令牌docID的点状生成排序表达力优于双编码器。随后，我们提出了SToICaL——一种简单的令牌-项目校准损失——可以在点化设置中，在项目和令牌层面都包含排名感知监督。我们运行一系列基于WordNet（Fellbaum， 1998）和ESCI（Reddy等，arXiv：2206.06588）的排序任务实验。SToICaL的两种变体成功抑制了无效docID生成的概率，并在常见排名指标上提升了超越前一检索的水平。

# 2026-01-13
https://papers.cool/arxiv/cs.IR?date=2026-01-13&show=50

## 2. [R3] GAP-Net：通过门控自适应渐进学习校准用户意图以实现点击率预测

https://papers.cool/arxiv/2601.07613

Authors: Ke Shenqiang, Wei Jianxiong, Hua Qingsong

Summary: 顺序用户行为建模对于点击率（CTR）预测至关重要，但却受到三个内在瓶颈的阻碍：（1）“注意力消耗”现象，即标准Softmax强制模型将概率质量分配给噪声行为;（2）静态查询假设，忽略了由实时上下文驱动的用户意图动态变化;以及（3）僵化视图聚合，无法根据决策上下文自适应地加权异构时间信号。为弥合这些空白，我们提出了GAP-Net（门控自适应渐进网络），这是一个统一框架，建立“三重门控”架构，逐步精炼从微观特征到宏观视角的信息。GAP-Net通过三种整合机制运行：（1）自适应稀疏门控注意力（ASGA）采用微观门控强制稀疏性，有效抑制大规模噪声激活;（2） 门控级联查询校准（GCQC）通过中层级级联通道，动态对齐实时触发器和长期记忆;以及（3）上下文门控去噪融合（CGDF）执行宏级调制，以协调多视图序列的聚合。工业数据集上的大量实验表明，GAP-Net相较于最先进的基线实现了显著改进，在对相互作用噪声和意图漂移方面表现出更优越的鲁棒性。

# 2026-01-14
https://papers.cool/arxiv/cs.IR?date=2026-01-14

## 3. [R2] RMBRec：针对目标行为的强健多行为推荐

https://papers.cool/arxiv/2601.08705


Authors: Miaomiao Cai, Zhijie Zhang, Junfeng Fang, Zhiyong Cheng, Xiang Wang, Meng Wang


Summary: 多行为推荐在实践中面临一个关键挑战：辅助行为（如点击、购物车）常常噪声较大、相关性弱或语义上与目标行为（如购买）不一致，导致偏好学习偏颇和性能不佳。虽然现有方法试图融合这些异构信号，但它们本质上缺乏确保对此类行为不一致的鲁棒性机制。在本研究中，我们提出了针对目标行为的强健多行为推荐（RMBRec），这是一个基于信息理论鲁棒性原则的稳健多行为推荐框架。我们将鲁棒性解释为最大化预测信息、同时最小化其在异质行为环境中的变异性的联合过程。在此视角下，表示鲁棒性模块（RRM）通过最大化用户辅助与目标表示之间的互信息来增强局部语义一致性，而优化鲁棒性模块（ORM）通过最小化行为间预测风险的方差来实现全局稳定性，这是对不变风险最小化的高效近似。这种本地-全球合作以理论连贯的方式连接了表示、纯化和优化的不变性。在三个真实世界数据集上的广泛实验表明，RMBRec不仅在准确性上优于最先进方法，还在各种噪声扰动下保持了显著的稳定性。为了可复现，我们的代码可在 https://github.com/miaomiao-cai2/RMBRec/ 获取。

# 2026-01-15

https://papers.cool/arxiv/cs.IR?date=2026-01-15

## 4. [R2] 为什么不在双视图中实现协作过滤？稀疏模型与稠密模型的桥接

https://papers.cool/arxiv/2601.09286


Authors: Hanze Guo, Jianxun Lian, Xiao Zhou


Summary: 协作过滤（CF）仍然是现代推荐系统的核心，目前以密集嵌入为基础的方法主导着实践。然而，这些方法存在一个关键局限：我们的理论分析揭示了在建模不受欢迎项目时存在基本的信噪比（SNR）上限，即基于参数的密集模型在严重数据稀疏时信噪比会减弱。为克服这一瓶颈，我们提出了 SaD（稀疏与稠密）这一统一框架，将密集嵌入的语义表达性与稀疏交互模式的结构可靠性整合在一起。我们理论上证明，对齐这些对偶视角可获得严格优越的全局信噪比。具体来说，SaD引入了一种轻量级的双向对齐机制：稠密视图通过注入语义相关来丰富稀疏视图，而稀疏视图则通过显式结构信号正则化稠密模型。大量实验表明，在这种双视角对齐下，即使是简单的矩阵分解式致密模型也能达到最先进的性能。此外，SaD即插即用，可无缝应用于多种现有推荐模型，凸显了从双重视角运用协作过滤的持久力量。进一步的现实基准评估显示，SaD始终优于强基线，位列BarsMatch排行榜第一。该代码公开于 https://github.com/harris26-G/SaD。

# 2026-01-16
https://papers.cool/arxiv/cs.IR?date=2026-01-16

## 5. [R3] STCRank：快手电子商店互动推荐系统时空协作排名

https://papers.cool/arxiv/2601.10027


Authors: Boyang Xia, Ruilin Bao, Hanjun Jiang, Jun Wang, Wenwu Ou


Summary: 作为一个受欢迎的电商平台，快手电购每天为数千万用户提供精准的个性化产品推荐。为了更好地响应实时用户反馈，我们已在核心首页推荐系统之外部署了交互式推荐系统（IRS）。该IRS由用户点击首页触发，并根据点击的项目生成一系列高度相关的推荐，以满足重点浏览需求。与传统电商RecSys不同，全屏UI和沉浸式滑动功能为常规排名系统带来了两个明显挑战。首先，排名目标之间存在明确的干扰（重叠或冲突），即转换、查看和滑动。这是因为在沉浸式浏览和滑动功能这一前提下，存在内在的行为共现。其次，排名系统在顺序推荐槽切换中容易出现时间贪婪陷阱，这源于全屏界面设计。为缓解这些挑战，我们提出了一种新的时空协作排序（STCRank）框架，以实现一个空间槽内多目标之间的协作，以及多个顺序重归槽之间的协作。在多目标协作（MOC）模块中，我们通过缓解目标重叠和冲突，推动了帕累托的前沿。在多槽协作（MSC）模块中，我们通过双阶段前瞻排序机制实现整体顺序槽位的全局最优。大量实验表明，我们提出的方法能够带来购买和DAU共同增长。该拟议系统自2025.6年起已在快兽E-shop部署。

## 6. [R3] 通过噪声感知共重置选择实现高效的内容推荐模型训练

https://papers.cool/arxiv/2601.10067


Authors: Hung Vinh Tran, Tong Chen, Hechuan Wen, Quoc Viet Hung Nguyen, Bin Cui, Hongzhi Yin


Summary: 基于内容的推荐系统（CRS）利用内容特征预测用户与项目的互动，是帮助用户导航信息丰富网络服务的重要工具。然而，要确保CRS的有效性，需要大规模甚至持续的模型训练，以适应不同的用户偏好，这导致了显著的计算成本和资源需求。解决这一挑战的一种有前景的方法是核心集选择，它识别出一个小而具代表性的数据样本子集，既保持模型质量，又能减少训练开销。然而，所选核心集在用户与物品交互中存在普遍噪声影响，尤其是在体积极小时。为此，我们提出了噪声感知共重置选择（Noise-aware Coreset Selection，NaCS），这是一个专门用于 CRS 的框架。NaCS 通过基于训练梯度的子模块化优化构建核心集，同时利用渐进训练模型纠正噪声标记。同时，我们通过不确定性量化过滤掉低置信样本，从而避免训练不可靠的交互作用。通过大量实验，我们表明NaCS在实现更高效率的同时，为CRS产出更高质量的核心集。值得注意的是，NaCS仅用1/%的训练数据就能恢复93%-95%的全数据集训练性能。源代码可在 \href{https://github.com/chenxing1999/nacs}{https://github.com/chenxing1999/nacs} 获取。