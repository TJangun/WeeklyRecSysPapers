### Abstract
[åŸæ–‡æ®µè½]
We present a unified multi-objective model for targeting both advertisements and promotions within the Spotify podcast ecosystem. Our approach addresses key challenges in personalization and cold-start initialization, particularly for new advertising objectives. By leveraging transfer learning from large-scale ad and content interactions within a multi-task learning (MTL) framework, a single joint model can be fine-tuned or directly applied to new or low-data targeting tasks, including in-app promotions. This multi-objective design jointly optimizes podcast outcomes such as streams, clicks, and follows for both ads and promotions using a shared representation over user, content, context, and creative features, effectively supporting diverse business goals while improving user experience.
Online A/B tests show up to a 22% reduction in effective Cost-Per-Stream (eCPS), particularly for less-streamed podcasts, and an 18â€“24% increase in podcast stream rates. Offline experiments and ablations highlight the contribution of ancillary objectives and feature groups to cold-start performance. Our experience shows that a unified modeling strategy improves maintainability, cold-start performance, and coverage, while breaking down historically siloed targeting pipelines. We discuss practical trade-offs of such joint models in a real-world advertising system.

[ä¸­æ–‡ç¿»è¯‘]
æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„å¤šç›®æ ‡æ¨¡å‹ï¼Œç”¨äºåœ¨Spotifyæ’­å®¢ç”Ÿæ€ç³»ç»Ÿä¸­åŒæ—¶å®ç°å¹¿å‘ŠæŠ•æ”¾å’Œæ¨å¹¿å†…å®¹å®šå‘ã€‚è¯¥æ–¹æ³•è§£å†³äº†ä¸ªæ€§åŒ–æ¨èå’Œå†·å¯åŠ¨åˆå§‹åŒ–ä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œå°¤å…¶é’ˆå¯¹æ–°çš„å¹¿å‘Šç›®æ ‡åœºæ™¯ã€‚é€šè¿‡åœ¨å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰æ¡†æ¶ä¸­åˆ©ç”¨æ¥è‡ªå¤§è§„æ¨¡å¹¿å‘Šå’Œå†…å®¹äº¤äº’æ•°æ®çš„è¿ç§»å­¦ä¹ ï¼Œå•ä¸ªè”åˆæ¨¡å‹å¯ç»è¿‡å¾®è°ƒæˆ–ç›´æ¥åº”ç”¨äºæ–°çš„æˆ–ä½æ•°æ®é‡çš„å®šå‘ä»»åŠ¡ï¼ŒåŒ…æ‹¬åº”ç”¨å†…æ¨å¹¿ã€‚è¿™ç§å¤šç›®æ ‡è®¾è®¡é€šè¿‡å¯¹ç”¨æˆ·ã€å†…å®¹ã€åœºæ™¯å’Œåˆ›æ„ç‰¹å¾æ„å»ºå…±äº«è¡¨ç¤ºï¼Œè”åˆä¼˜åŒ–å¹¿å‘Šå’Œæ¨å¹¿çš„æ’­å®¢ç›¸å…³æˆæœï¼ˆå¦‚æ’­æ”¾é‡ã€ç‚¹å‡»é‡å’Œå…³æ³¨é‡ï¼‰ï¼Œåœ¨æœ‰æ•ˆæ”¯æŒå¤šæ ·åŒ–ä¸šåŠ¡ç›®æ ‡çš„åŒæ—¶æå‡ç”¨æˆ·ä½“éªŒã€‚
çº¿ä¸ŠA/Bæµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œæœ‰æ•ˆæ¯æ’­æ”¾æˆæœ¬ï¼ˆeCPSï¼‰æœ€é«˜é™ä½22%ï¼ˆå°¤å…¶é’ˆå¯¹æ’­æ”¾é‡è¾ƒå°‘çš„æ’­å®¢ï¼‰ï¼Œæ’­å®¢æ’­æ”¾ç‡æå‡18%-24%ã€‚ç¦»çº¿å®éªŒå’Œæ¶ˆèåˆ†æçªæ˜¾äº†è¾…åŠ©ç›®æ ‡å’Œç‰¹å¾ç»„å¯¹å†·å¯åŠ¨æ€§èƒ½çš„ç§¯æä½œç”¨ã€‚å®è·µè¡¨æ˜ï¼Œç»Ÿä¸€å»ºæ¨¡ç­–ç•¥æå‡äº†æ¨¡å‹çš„å¯ç»´æŠ¤æ€§ã€å†·å¯åŠ¨æ€§èƒ½å’Œè¦†ç›–èŒƒå›´ï¼ŒåŒæ—¶æ‰“ç ´äº†å†å²ä¸Šç›¸äº’ç‹¬ç«‹çš„å®šå‘æµç¨‹ã€‚æœ¬æ–‡è¿˜æ¢è®¨äº†æ­¤ç±»è”åˆæ¨¡å‹åœ¨å®é™…å¹¿å‘Šç³»ç»Ÿä¸­çš„å®é™…æƒè¡¡é—®é¢˜ã€‚

### CCS Concepts
[åŸæ–‡æ®µè½]
â€¢ Information systems ï¿«Computational advertising; Recommender systems; Online advertising; â€¢ Computing methodologies ï¿«Multi-task learning.

[ä¸­æ–‡ç¿»è¯‘]
â€¢ ä¿¡æ¯ç³»ç»Ÿ ï¿«è®¡ç®—å¹¿å‘Šï¼›æ¨èç³»ç»Ÿï¼›åœ¨çº¿å¹¿å‘Šï¼›â€¢ è®¡ç®—æ–¹æ³• ï¿«å¤šä»»åŠ¡å­¦ä¹ ã€‚

### Keywords
[åŸæ–‡æ®µè½]
Online advertising; Multi-task learning; Recommender systems

[ä¸­æ–‡ç¿»è¯‘]
åœ¨çº¿å¹¿å‘Šï¼›å¤šä»»åŠ¡å­¦ä¹ ï¼›æ¨èç³»ç»Ÿ

### ACM Reference Format
[åŸæ–‡æ®µè½]
Shivam Verma, Hannes Karlbom, Yu Zhao, Nick Topping, Vivian Chen, Kieran Stanley, and Bharath Rengarajan. 2026. Cold-Starting Podcast Ads and Promotions with Multi-Task Learning on Spotify. In Proceedings of the Nineteenth ACM International Conference on Web Search and Data Mining (WSDM â€™26), February 22â€“26, 2026, Boise, ID, USA. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3773966.3779388

[ä¸­æ–‡ç¿»è¯‘]
Shivam Vermaã€Hannes Karlbomã€Yu Zhaoã€Nick Toppingã€Vivian Chenã€Kieran Stanley å’Œ Bharath Rengarajan. 2026. åŸºäºå¤šä»»åŠ¡å­¦ä¹ çš„Spotifyæ’­å®¢å¹¿å‘Šä¸æ¨å¹¿å†·å¯åŠ¨æ–¹æ¡ˆ. ç¬¬åä¹å±ŠACMå›½é™…ç½‘ç»œæœç´¢ä¸æ•°æ®æŒ–æ˜ä¼šè®®è®ºæ–‡é›†ï¼ˆWSDM â€™26ï¼‰, 2026å¹´2æœˆ22æ—¥-26æ—¥, ç¾å›½çˆ±è¾¾è·å·åšä¼Šè¥¿. ACMå‡ºç‰ˆç¤¾, ç¾å›½çº½çº¦å·çº½çº¦å¸‚, 5é¡µ. https://doi.org/10.1145/3773966.3779388

### 1 Motivation
[åŸæ–‡æ®µè½]
Spotify, with its user base of over 700 million, identifies podcasts as a significant and rapidly growing content vertical, making effective personalization crucial for listener engagement, monetization (especially for over 400 million ad-supported users), and the discovery and growth of podcast creators. The platform supports diverse business objectives, from driving initial streams for new episodes to optimizing impression-to-stream rates (i2s) and clickthrough rates (CTR), with a particular focus on boosting visibility for less-streamed creators who suffer from cold-start issues due to data scarcity. Two primary mechanisms connect users with podcast content: advertisements (ads), such as in-stream audio or video placements (Fig. 1a, 1b), and promotions, which surface strategically important or relevant content like display promotions for Spotify Originals (Fig. 1c). Despite different immediate objectives (an ad click versus a direct stream from a promotion), both channels share the goal of matching users with relevant and engaging podcasts, driven by similar user signals (e.g., listening history, explicit follows) and content affinities (e.g., genre, topics). Positive interactions in one channel can therefore inform decisions in the other.

[ä¸­æ–‡ç¿»è¯‘]
Spotifyæ‹¥æœ‰è¶…è¿‡7äº¿ç”¨æˆ·ï¼Œå°†æ’­å®¢è§†ä¸ºé‡è¦ä¸”å¿«é€Ÿå¢é•¿çš„å†…å®¹é¢†åŸŸã€‚æœ‰æ•ˆçš„ä¸ªæ€§åŒ–æ¨èå¯¹äºæå‡å¬ä¼—å‚ä¸åº¦ã€å®ç°å•†ä¸šåŒ–ï¼ˆå°¤å…¶é’ˆå¯¹4äº¿å¤šå¹¿å‘Šæ”¯æŒç”¨æˆ·ï¼‰ä»¥åŠåŠ©åŠ›æ’­å®¢åˆ›ä½œè€…çš„å†…å®¹å‘ç°ä¸æˆé•¿è‡³å…³é‡è¦ã€‚è¯¥å¹³å°æ”¯æŒå¤šæ ·åŒ–çš„ä¸šåŠ¡ç›®æ ‡ï¼Œä»ä¸ºæ–°å‰§é›†è·å–åˆå§‹æ’­æ”¾é‡ï¼Œåˆ°ä¼˜åŒ–æ›å…‰-æ’­æ”¾è½¬åŒ–ç‡ï¼ˆi2sï¼‰å’Œç‚¹å‡»ç‡ï¼ˆCTRï¼‰ï¼ŒåŒæ—¶ç‰¹åˆ«å…³æ³¨é‚£äº›å› æ•°æ®ç¨€ç¼ºè€Œé¢ä¸´å†·å¯åŠ¨é—®é¢˜çš„ä½æ’­æ”¾é‡åˆ›ä½œè€…ï¼Œè‡´åŠ›äºæå‡å…¶å†…å®¹æ›å…‰åº¦ã€‚è¿æ¥ç”¨æˆ·ä¸æ’­å®¢å†…å®¹çš„ä¸¤å¤§æ ¸å¿ƒæœºåˆ¶ä¸ºï¼šå¹¿å‘Šï¼ˆå¦‚æµå†…éŸ³é¢‘æˆ–è§†é¢‘å¹¿å‘ŠæŠ•æ”¾ï¼Œè§å›¾1aã€1bï¼‰å’Œæ¨å¹¿ï¼ˆå³å±•ç¤ºå…·æœ‰æˆ˜ç•¥é‡è¦æ€§æˆ–ç›¸å…³æ€§çš„å†…å®¹ï¼Œå¦‚SpotifyåŸåˆ›æ’­å®¢çš„å±•ç¤ºæ¨å¹¿ï¼Œè§å›¾1cï¼‰ã€‚å°½ç®¡ä¸¤è€…çš„ç›´æ¥ç›®æ ‡ä¸åŒï¼ˆå¹¿å‘Šè¿½æ±‚ç‚¹å‡»é‡ï¼Œæ¨å¹¿è¿½æ±‚ç›´æ¥æ’­æ”¾é‡ï¼‰ï¼Œä½†ä¸¤å¤§æ¸ é“çš„æ ¸å¿ƒç›®æ ‡ä¸€è‡´â€”â€”ä¸ºç”¨æˆ·åŒ¹é…ç›¸å…³ä¸”æœ‰å¸å¼•åŠ›çš„æ’­å®¢ï¼Œä¸”å‡ä¾èµ–ç›¸ä¼¼çš„ç”¨æˆ·ä¿¡å·ï¼ˆå¦‚æ”¶å¬å†å²ã€ä¸»åŠ¨å…³æ³¨ï¼‰å’Œå†…å®¹åå¥½ï¼ˆå¦‚ç±»å‹ã€ä¸»é¢˜ï¼‰ã€‚å› æ­¤ï¼Œä¸€ä¸ªæ¸ é“ä¸­çš„æ­£å‘äº¤äº’æ•°æ®å¯ä¸ºå¦ä¸€ä¸ªæ¸ é“çš„å†³ç­–æä¾›å‚è€ƒã€‚

[åŸæ–‡å›¾æ³¨]
Figure 1: Left to right: (a) An in-stream podcast audio ad. (b) An in-stream unmuted podcast video ad. (c) A display promotion for a Spotify Original podcast.

[ä¸­æ–‡ç¿»è¯‘]
å›¾1ï¼šä»å·¦è‡³å³ï¼š(a) æµå†…æ’­å®¢éŸ³é¢‘å¹¿å‘Šï¼›(b) æµå†…éé™éŸ³æ’­å®¢è§†é¢‘å¹¿å‘Šï¼›(c) SpotifyåŸåˆ›æ’­å®¢çš„å±•ç¤ºæ¨å¹¿ã€‚

[åŸæ–‡æ®µè½]
Historically, these objectives were handled by separate, specialized machine learning models. For example, a model optimizing i2s for a Home-page promotion would be distinct from a model optimizing clicks on an audio ad for a new podcast series. This siloed, task-specific approach created several challenges. First, slow innovation: introducing new business or ad objectives requires building new models from scratch, involving substantial engineering, data collection, and A/B testing, which can slow the rollout of tools that help podcasters reach relevant audiences. Second, the cold-start problem for optimization objectives: newly introduced ad or promotional products for specific audiences, such as the â€œlikelihood to stream advertised content after an adâ€ for emerging or new creators, often lack sufficient interaction data to train high-performing specialized models, hampering the discoverability of these less-streamed creators. Third, inefficiency and missed synergies: separate pipelines made it difficult to exploit shared latent patterns and overlapping signals across podcast ads and promotions, and led to siloed teams building similar models for related products.

[ä¸­æ–‡ç¿»è¯‘]
å†å²ä¸Šï¼Œè¿™äº›ç›®æ ‡ç”±ç›¸äº’ç‹¬ç«‹çš„ä¸“ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹åˆ†åˆ«å¤„ç†ã€‚ä¾‹å¦‚ï¼Œä¼˜åŒ–é¦–é¡µæ¨å¹¿æ›å…‰-æ’­æ”¾è½¬åŒ–ç‡ï¼ˆi2sï¼‰çš„æ¨¡å‹ï¼Œä¸ä¼˜åŒ–æ–°æ’­å®¢ç³»åˆ—éŸ³é¢‘å¹¿å‘Šç‚¹å‡»ç‡çš„æ¨¡å‹æ˜¯å®Œå…¨åˆ†ç¦»çš„ã€‚è¿™ç§ç‹¬ç«‹çš„ã€é¢å‘ç‰¹å®šä»»åŠ¡çš„æ–¹æ³•å¸¦æ¥äº†è¯¸å¤šæŒ‘æˆ˜ï¼šé¦–å…ˆï¼Œåˆ›æ–°é€Ÿåº¦ç¼“æ…¢â€”â€”å¼•å…¥æ–°çš„ä¸šåŠ¡æˆ–å¹¿å‘Šç›®æ ‡éœ€è¦ä»é›¶æ„å»ºæ–°æ¨¡å‹ï¼Œæ¶‰åŠå¤§é‡å·¥ç¨‹å¼€å‘ã€æ•°æ®æ”¶é›†å’ŒA/Bæµ‹è¯•å·¥ä½œï¼Œè¿™ä¼šå»¶ç¼“åŠ©åŠ›æ’­å®¢åˆ›ä½œè€…è§¦è¾¾ç›®æ ‡å—ä¼—çš„å·¥å…·è½åœ°é€Ÿåº¦ï¼›å…¶æ¬¡ï¼Œä¼˜åŒ–ç›®æ ‡çš„å†·å¯åŠ¨é—®é¢˜â€”â€”é’ˆå¯¹ç‰¹å®šå—ä¼—çš„æ–°å¹¿å‘Šæˆ–æ¨å¹¿äº§å“ï¼ˆå¦‚é¢å‘æ–°å…´åˆ›ä½œè€…çš„â€œå¹¿å‘Šåæ’­æ”¾å¹¿å‘Šå†…å®¹çš„å¯èƒ½æ€§â€é¢„æµ‹ï¼‰å¾€å¾€ç¼ºä¹è¶³å¤Ÿçš„äº¤äº’æ•°æ®æ¥è®­ç»ƒé«˜æ€§èƒ½ä¸“ç”¨æ¨¡å‹ï¼Œä»è€Œé˜»ç¢äº†è¿™äº›ä½æ’­æ”¾é‡åˆ›ä½œè€…çš„å†…å®¹å‘ç°ï¼›ç¬¬ä¸‰ï¼Œæ•ˆç‡ä½ä¸‹ä¸”é”™å¤±ååŒæ•ˆåº”â€”â€”ç‹¬ç«‹çš„æµç¨‹éš¾ä»¥æŒ–æ˜æ’­å®¢å¹¿å‘Šå’Œæ¨å¹¿ä¹‹é—´çš„å…±äº«æ½œåœ¨æ¨¡å¼ä¸é‡å ä¿¡å·ï¼ŒåŒæ—¶å¯¼è‡´ç‹¬ç«‹å›¢é˜Ÿä¸ºç›¸å…³äº§å“æ„å»ºç›¸ä¼¼æ¨¡å‹ï¼Œé€ æˆèµ„æºå†—ä½™ã€‚

[åŸæ–‡æ®µè½]
These challenges motivated our exploration of a unified objective optimization approach via multi-task learning (MTL).

[ä¸­æ–‡ç¿»è¯‘]
è¿™äº›æŒ‘æˆ˜ä¿ƒä½¿æˆ‘ä»¬æ¢ç´¢åŸºäºå¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰çš„ç»Ÿä¸€ç›®æ ‡ä¼˜åŒ–æ–¹æ³•ã€‚

### 2 Related Work
[åŸæ–‡æ®µè½]
Multi-task learning improves performance by jointly learning related tasks [5â€“7, 11, 13, 14, 16, 17, 26], facilitating transfer from data-rich advertising tasks to data-scarce promotional ones (and vice versa), thereby addressing cold-start issues for newer and smaller creators. By modeling ads and promotions together, we aim to consolidate learning, reduce duplication across systems, and accelerate new capability deployment, ultimately improving personalization for listeners and growth for creators. Our contribution focuses on bridging organizational silos by grouping tasks based on business goal alignment in multi-stakeholder and multi-objective settings [8, 9, 15, 17, 19, 25, 29], which is crucial for balancing diverse business objectives.

[ä¸­æ–‡ç¿»è¯‘]
å¤šä»»åŠ¡å­¦ä¹ é€šè¿‡è”åˆå­¦ä¹ ç›¸å…³ä»»åŠ¡æ¥æå‡æ€§èƒ½[5-7, 11, 13, 14, 16, 17, 26]ï¼Œèƒ½å¤Ÿä¿ƒè¿›ä»æ•°æ®ä¸°å¯Œçš„å¹¿å‘Šä»»åŠ¡å‘æ•°æ®ç¨€ç¼ºçš„æ¨å¹¿ä»»åŠ¡çš„çŸ¥è¯†è¿ç§»ï¼ˆåä¹‹äº¦ç„¶ï¼‰ï¼Œä»è€Œè§£å†³æ–°å…´å’Œå°å‹åˆ›ä½œè€…çš„å†·å¯åŠ¨é—®é¢˜ã€‚é€šè¿‡å°†å¹¿å‘Šå’Œæ¨å¹¿è”åˆå»ºæ¨¡ï¼Œæˆ‘ä»¬æ—¨åœ¨æ•´åˆå­¦ä¹ è¿‡ç¨‹ã€å‡å°‘ç³»ç»Ÿé—´çš„é‡å¤å¼€å‘ã€åŠ é€Ÿæ–°åŠŸèƒ½éƒ¨ç½²ï¼Œæœ€ç»ˆæå‡å¬ä¼—çš„ä¸ªæ€§åŒ–ä½“éªŒå’Œåˆ›ä½œè€…çš„æˆé•¿ç©ºé—´ã€‚æˆ‘ä»¬çš„è´¡çŒ®é‡ç‚¹åœ¨äºï¼Œåœ¨å¤šåˆ©ç›Šç›¸å…³è€…å’Œå¤šç›®æ ‡åœºæ™¯ä¸‹ï¼Œé€šè¿‡åŸºäºä¸šåŠ¡ç›®æ ‡ä¸€è‡´æ€§å¯¹ä»»åŠ¡è¿›è¡Œåˆ†ç»„ï¼Œæ‰“ç ´ç»„ç»‡å±‚é¢çš„å£å’[8, 9, 15, 17, 19, 25, 29]ï¼Œè¿™å¯¹äºå¹³è¡¡å¤šæ ·åŒ–çš„ä¸šåŠ¡ç›®æ ‡è‡³å…³é‡è¦ã€‚

[åŸæ–‡æ®µè½]
Multi-Task Learning in Industry Recommenders. MTL improves generalization by jointly learning related objectives [3]. At industrial scale, platforms have adopted MTL to couple heterogeneous business goals such as engagement, satisfaction, and monetization [1, 7, 16, 20, 24, 26, 28], highlighting the value of shared representations while carefully managing interference. Our work follows this line but specifically targets the joint modeling of podcast ads and promotions within a single framework.

[ä¸­æ–‡ç¿»è¯‘]
å·¥ä¸šç•Œæ¨èç³»ç»Ÿä¸­çš„å¤šä»»åŠ¡å­¦ä¹ ã€‚å¤šä»»åŠ¡å­¦ä¹ é€šè¿‡è”åˆå­¦ä¹ ç›¸å…³ç›®æ ‡æå‡æ³›åŒ–èƒ½åŠ›[3]ã€‚åœ¨å·¥ä¸šçº§è§„æ¨¡ä¸‹ï¼Œå„å¤§å¹³å°å·²é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ æ¥æ•´åˆä¸åŒçš„ä¸šåŠ¡ç›®æ ‡ï¼Œå¦‚å‚ä¸åº¦ã€æ»¡æ„åº¦å’Œå•†ä¸šåŒ–æ”¶ç›Š[1, 7, 16, 20, 24, 26, 28]ï¼Œè¿™å‡¸æ˜¾äº†å…±äº«è¡¨ç¤ºçš„ä»·å€¼ï¼ŒåŒæ—¶éœ€è¦è°¨æ…å¤„ç†ä»»åŠ¡é—´çš„å¹²æ‰°ã€‚æˆ‘ä»¬çš„ç ”ç©¶éµå¾ªè¿™ä¸€æ–¹å‘ï¼Œä½†ä¸“æ³¨äºåœ¨å•ä¸€æ¡†æ¶å†…å®ç°æ’­å®¢å¹¿å‘Šå’Œæ¨å¹¿çš„è”åˆå»ºæ¨¡ã€‚

[åŸæ–‡æ®µè½]
Joint Optimization and Task Relatedness. A central challenge in MTL is trading off objectives that may conflict. Viewing MTL as multi-objective optimization provides principled ways to navigate Pareto trade-offs [2, 8, 11, 17, 29]. Another line of work studies when tasks should be learned together, showing that task affinity or relatedness strongly affects transfer [19]. In our setting, we unify advertising and promotions within one model because they share user and content signals, while still needing to control cross-objective interference.

[ä¸­æ–‡ç¿»è¯‘]
è”åˆä¼˜åŒ–ä¸ä»»åŠ¡ç›¸å…³æ€§ã€‚å¤šä»»åŠ¡å­¦ä¹ çš„æ ¸å¿ƒæŒ‘æˆ˜ä¹‹ä¸€æ˜¯å¯¹å¯èƒ½å†²çªçš„ç›®æ ‡è¿›è¡Œæƒè¡¡ã€‚å°†å¤šä»»åŠ¡å­¦ä¹ è§†ä¸ºå¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼Œä¸ºå¤„ç†å¸•ç´¯æ‰˜æƒè¡¡æä¾›äº†åŸåˆ™æ€§æ–¹æ³•[2, 8, 11, 17, 29]ã€‚å¦ä¸€ç±»ç ”ç©¶æ¢è®¨äº†ä»»åŠ¡åº”ä½•æ—¶è”åˆå­¦ä¹ ï¼Œç»“æœè¡¨æ˜ä»»åŠ¡é—´çš„å…³è”æ€§æˆ–ç›¸ä¼¼æ€§å¯¹çŸ¥è¯†è¿ç§»æ•ˆæœæœ‰æ˜¾è‘—å½±å“[19]ã€‚åœ¨æˆ‘ä»¬çš„åœºæ™¯ä¸­ï¼Œç”±äºå¹¿å‘Šå’Œæ¨å¹¿å…±äº«ç”¨æˆ·å’Œå†…å®¹ä¿¡å·ï¼Œå› æ­¤å°†å…¶æ•´åˆåˆ°åŒä¸€æ¨¡å‹ä¸­ï¼Œä½†åŒæ—¶ä»éœ€æ§åˆ¶è·¨ç›®æ ‡çš„å¹²æ‰°ã€‚

[åŸæ–‡æ®µè½]
Mitigating Negative Transfer. Negative transfer arises when gradients from different objectives conflict. Industry-ready approaches include learning to weight task losses (e.g., uncertainty weighting) [10], gradient balancing/normalization [4], and gradient surgery to resolve conflicts (PCGrad) [27], as well as work on stabilizing large-scale multitask ranking models in production [23]. Architectural remedies such as MMoE share experts with task-specific gating to reduce interference at scale [14], and PLE introduces progressive shared/specific towers to further curb negative transfer in recommendation tasks [22]. Our approach combines unified modeling with imbalance-aware training and careful sharing to retain positive transfer while limiting interference.

[ä¸­æ–‡ç¿»è¯‘]
è´Ÿè¿ç§»ç¼“è§£ã€‚å½“ä¸åŒç›®æ ‡çš„æ¢¯åº¦å‘ç”Ÿå†²çªæ—¶ï¼Œä¼šäº§ç”Ÿè´Ÿè¿ç§»ã€‚å·¥ä¸šç•Œæˆç†Ÿçš„è§£å†³æ–¹æ¡ˆåŒ…æ‹¬å­¦ä¹ ä»»åŠ¡æŸå¤±æƒé‡ï¼ˆå¦‚ä¸ç¡®å®šæ€§åŠ æƒï¼‰[10]ã€æ¢¯åº¦å¹³è¡¡/å½’ä¸€åŒ–[4]ã€é€šè¿‡æ¢¯åº¦ä¿®æ­£è§£å†³å†²çªï¼ˆå¦‚PCGradï¼‰[27]ï¼Œä»¥åŠé’ˆå¯¹ç”Ÿäº§ç¯å¢ƒä¸­å¤§è§„æ¨¡å¤šä»»åŠ¡æ’åºæ¨¡å‹çš„ç¨³å®šæ€§ä¼˜åŒ–ç ”ç©¶[23]ã€‚æ¶æ„å±‚é¢çš„æ”¹è¿›æ–¹æ¡ˆåŒ…æ‹¬ï¼šMMoEé€šè¿‡ä»»åŠ¡ç‰¹å®šçš„é—¨æ§æœºåˆ¶å…±äº«ä¸“å®¶ç½‘ç»œï¼Œä»¥è§„æ¨¡åŒ–å‡å°‘å¹²æ‰°[14]ï¼›PLEå¼•å…¥æ¸è¿›å¼å…±äº«/ä¸“ç”¨å¡”ç»“æ„ï¼Œè¿›ä¸€æ­¥æŠ‘åˆ¶æ¨èä»»åŠ¡ä¸­çš„è´Ÿè¿ç§»[22]ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ç»Ÿä¸€å»ºæ¨¡ä¸ä¸å¹³è¡¡æ„ŸçŸ¥è®­ç»ƒç›¸ç»“åˆï¼Œå¹¶é€šè¿‡è°¨æ…çš„å‚æ•°å…±äº«ç­–ç•¥ï¼Œåœ¨ä¿ç•™æ­£è¿ç§»çš„åŒæ—¶é™åˆ¶è´Ÿè¿ç§»ã€‚

### 3 System Evolution and Architecture

[åŸæ–‡æ®µè½]
We evolved from specialized models to a unified multi-task learning (MTL) framework that jointly optimizes podcast-related ad and promotion objectives. We first summarize the baselines and then formalize the joint adsâ€“promotions model, including task definitions and training setup.

[ä¸­æ–‡ç¿»è¯‘]
æˆ‘ä»¬çš„ç³»ç»Ÿä»ä¸“ç”¨æ¨¡å‹é€æ­¥æ¼”è¿›ä¸ºç»Ÿä¸€çš„å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯è”åˆä¼˜åŒ–ä¸æ’­å®¢ç›¸å…³çš„å¹¿å‘Šå’Œæ¨å¹¿ç›®æ ‡ã€‚æœ¬èŠ‚é¦–å…ˆæ¦‚è¿°åŸºå‡†æ¨¡å‹ï¼Œç„¶åå½¢å¼åŒ–å®šä¹‰å¹¿å‘Š-æ¨å¹¿è”åˆæ¨¡å‹ï¼ŒåŒ…æ‹¬ä»»åŠ¡å®šä¹‰å’Œè®­ç»ƒè®¾ç½®ã€‚

#### 3.1 Baseline Models and Initial Approaches
[åŸæ–‡æ®µè½]
Figure 2A shows our initial promotions-only multi-task model. Each training example is an impression of a podcast promotion shown to a user. A shared feature encoder (with post-batch norm application) feeds task-specific towers-stacked MLPs-that predict userâ€“podcast interactions (e.g., stream, click, like, follow) for promotions.

[ä¸­æ–‡ç¿»è¯‘]
å›¾2Aå±•ç¤ºäº†æˆ‘ä»¬æœ€åˆçš„ä»…é¢å‘æ¨å¹¿çš„å¤šä»»åŠ¡æ¨¡å‹ã€‚æ¯ä¸ªè®­ç»ƒæ ·æœ¬å¯¹åº”ä¸€æ¬¡å‘ç”¨æˆ·å±•ç¤ºçš„æ’­å®¢æ¨å¹¿æ›å…‰è®°å½•ã€‚å…±äº«ç‰¹å¾ç¼–ç å™¨ï¼ˆåº”ç”¨æ‰¹é‡å½’ä¸€åŒ–åå¤„ç†ï¼‰å°†ç‰¹å¾è¾“å…¥ä»»åŠ¡ä¸“ç”¨å¡”ç»“æ„ï¼ˆå †å çš„å¤šå±‚æ„ŸçŸ¥å™¨ï¼‰ï¼Œè¯¥å¡”ç»“æ„ç”¨äºé¢„æµ‹æ¨å¹¿åœºæ™¯ä¸‹çš„ç”¨æˆ·-æ’­å®¢äº¤äº’è¡Œä¸ºï¼ˆå¦‚æ’­æ”¾ã€ç‚¹å‡»ã€ç‚¹èµã€å…³æ³¨ï¼‰ã€‚

[åŸæ–‡æ®µè½]
The encoder consumes four feature groups: (1) user signals (historical listening, follows, search interactions, high-level profile attributes), (2) content signals (show and episode identifiers, learned embeddings, genres, topics), (3) context (time, surface, session state), and (4) promotion metadata (slot, layout, campaign). We also considered Mixture-of-Experts (MoE) [12, 14, 18, 21] variants, but the shared-bottom model served as the main production baseline.

[ä¸­æ–‡ç¿»è¯‘]
ç¼–ç å™¨æ¥æ”¶å››ç±»ç‰¹å¾ç»„ï¼š(1) ç”¨æˆ·ä¿¡å·ï¼ˆå†å²æ”¶å¬è®°å½•ã€å…³æ³¨åˆ—è¡¨ã€æœç´¢äº¤äº’ã€é«˜å±‚ç”¨æˆ·ç”»åƒå±æ€§ï¼‰ï¼›(2) å†…å®¹ä¿¡å·ï¼ˆèŠ‚ç›®å’Œå‰§é›†æ ‡è¯†ã€å­¦ä¹ å¾—åˆ°çš„åµŒå…¥å‘é‡ã€ç±»å‹ã€ä¸»é¢˜ï¼‰ï¼›(3) åœºæ™¯ä¿¡æ¯ï¼ˆæ—¶é—´ã€å±•ç¤ºä½ç½®ã€ä¼šè¯çŠ¶æ€ï¼‰ï¼›(4) æ¨å¹¿å…ƒæ•°æ®ï¼ˆå¹¿å‘Šä½ã€å¸ƒå±€ã€æ´»åŠ¨ï¼‰ã€‚æˆ‘ä»¬ä¹Ÿè€ƒè™‘äº†æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰[12, 14, 18, 21]çš„å˜ä½“ï¼Œä½†å…±äº«åº•éƒ¨æ¨¡å‹ä»æ˜¯ç”Ÿäº§ç¯å¢ƒä¸­çš„ä¸»è¦åŸºå‡†æ¨¡å‹ã€‚

[åŸæ–‡æ®µè½]
Two intermediate approaches are shown in Figures 2A and 2B:
(1) Promotions model for ad cold-start. We reused the promotions model to score ad impressions. This enabled rapid launches for new ad objectives but ignored ad-specific features (e.g., creative type, campaign) and userâ€“ad interaction patterns.
(2) Single-task ads model. We built an ads-only model trained across all podcast ad surfaces and creatives (audio, video, display). It used similar user, content, and context features, plus ad-specific metadata (creative ID, format, campaign, slot). Despite rich ad logs, this single-task approach struggled to balance diverse business objectives effectively and support future goals requiring learning from all on-platform podcast interactions.

[ä¸­æ–‡ç¿»è¯‘]
å›¾2Aå’Œå›¾2Bå±•ç¤ºäº†ä¸¤ç§è¿‡æ¸¡æ€§æ–¹æ³•ï¼š
(1) ç”¨äºå¹¿å‘Šå†·å¯åŠ¨çš„æ¨å¹¿æ¨¡å‹ã€‚æˆ‘ä»¬å¤ç”¨æ¨å¹¿æ¨¡å‹å¯¹å¹¿å‘Šæ›å…‰è¿›è¡Œè¯„åˆ†ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿå¿«é€Ÿä¸Šçº¿æ–°çš„å¹¿å‘Šç›®æ ‡ï¼Œä½†å¿½ç•¥äº†å¹¿å‘Šä¸“ç”¨ç‰¹å¾ï¼ˆå¦‚åˆ›æ„ç±»å‹ã€æ´»åŠ¨ï¼‰å’Œç”¨æˆ·-å¹¿å‘Šäº¤äº’æ¨¡å¼ã€‚
(2) å•ä»»åŠ¡å¹¿å‘Šæ¨¡å‹ã€‚æˆ‘ä»¬æ„å»ºäº†ä»…é¢å‘å¹¿å‘Šçš„æ¨¡å‹ï¼Œè®­ç»ƒæ•°æ®è¦†ç›–æ‰€æœ‰æ’­å®¢å¹¿å‘Šå±•ç¤ºä½ç½®å’Œåˆ›æ„å½¢å¼ï¼ˆéŸ³é¢‘ã€è§†é¢‘ã€å±•ç¤ºç±»ï¼‰ã€‚è¯¥æ¨¡å‹ä½¿ç”¨ä¸æ¨å¹¿æ¨¡å‹ç›¸ä¼¼çš„ç”¨æˆ·ã€å†…å®¹å’Œåœºæ™¯ç‰¹å¾ï¼Œå¹¶è¡¥å……äº†å¹¿å‘Šä¸“ç”¨å…ƒæ•°æ®ï¼ˆåˆ›æ„IDã€æ ¼å¼ã€æ´»åŠ¨ã€å¹¿å‘Šä½ï¼‰ã€‚å°½ç®¡æ‹¥æœ‰ä¸°å¯Œçš„å¹¿å‘Šæ—¥å¿—ï¼Œä½†è¿™ç§å•ä»»åŠ¡æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¹³è¡¡å¤šæ ·åŒ–çš„ä¸šåŠ¡ç›®æ ‡ï¼Œä¹Ÿæ— æ³•æ”¯æŒéœ€è¦ä»å¹³å°å†…æ‰€æœ‰æ’­å®¢äº¤äº’ä¸­å­¦ä¹ çš„æœªæ¥ç›®æ ‡ã€‚

[åŸæ–‡æ®µè½]
Maintaining separate data pipelines and models increased engineering overhead and limited our ability to exploit shared structure across tasks, motivating a unified solution.

[ä¸­æ–‡ç¿»è¯‘]
ç»´æŠ¤ç‹¬ç«‹çš„æ•°æ®ç®¡é“å’Œæ¨¡å‹å¢åŠ äº†å·¥ç¨‹å¼€é”€ï¼Œä¸”é™åˆ¶äº†æˆ‘ä»¬æŒ–æ˜ä»»åŠ¡é—´å…±äº«ç»“æ„çš„èƒ½åŠ›ï¼Œè¿™ä¿ƒä½¿æˆ‘ä»¬å¯»æ±‚ç»Ÿä¸€çš„è§£å†³æ–¹æ¡ˆã€‚

[åŸæ–‡å›¾æ³¨]
Figure 2: (A) A promotions-only podcast model, used to serve ad stream predictions in the cold-start phase for the Ads objective. (B) Single-task p(ad stream) model incorporating both promotions and ads data. (C) Multi-task joint model for promotions and ads, serving both businesses.

[ä¸­æ–‡ç¿»è¯‘]
å›¾2ï¼š(A) ä»…é¢å‘æ¨å¹¿çš„æ’­å®¢æ¨¡å‹ï¼Œç”¨äºå¹¿å‘Šç›®æ ‡å†·å¯åŠ¨é˜¶æ®µçš„å¹¿å‘Šæ’­æ”¾é‡é¢„æµ‹ï¼›(B) å•ä»»åŠ¡å¹¿å‘Šæ’­æ”¾é‡é¢„æµ‹æ¨¡å‹ï¼Œæ•´åˆäº†æ¨å¹¿å’Œå¹¿å‘Šæ•°æ®ï¼›(C) å¹¿å‘Šä¸æ¨å¹¿è”åˆå¤šä»»åŠ¡æ¨¡å‹ï¼ŒåŒæ—¶æœåŠ¡äºä¸¤å¤§ä¸šåŠ¡åœºæ™¯ã€‚

#### 3.2 Problem Formulation for Joint Adsâ€“Promotions Modeling

[åŸæ–‡æ®µè½]
We treat targeting as predicting multiple per-impression outcomes for a userâ€“podcast pair \((u, c)\) in context \(###\) (e.g., surface, time, device). Let T be the set of binary prediction tasks, including:
â€¢ PromotionStream: Stream after a promotion impression;
â€¢ AdStream: Stream after an ad impression;
â€¢ Click: Click on a promotion or ad;
â€¢ Like or Follow: Like / follow of a promoted podcast.

[ä¸­æ–‡ç¿»è¯‘]
æˆ‘ä»¬å°†å®šå‘é—®é¢˜è§†ä¸ºï¼šåœ¨ç»™å®šåœºæ™¯ ###ï¼ˆå¦‚å±•ç¤ºä½ç½®ã€æ—¶é—´ã€è®¾å¤‡ï¼‰ä¸‹ï¼Œé¢„æµ‹ç”¨æˆ·-æ’­å®¢å¯¹$(u, c)$çš„å¤šä¸ªå•æ¬¡æ›å…‰ç»“æœã€‚è®¾Tä¸ºäºŒåˆ†ç±»é¢„æµ‹ä»»åŠ¡é›†åˆï¼ŒåŒ…æ‹¬ï¼š
â€¢ PromotionStreamï¼ˆæ¨å¹¿æ’­æ”¾ï¼‰ï¼šæ¨å¹¿æ›å…‰åäº§ç”Ÿæ’­æ”¾è¡Œä¸ºï¼›
â€¢ AdStreamï¼ˆå¹¿å‘Šæ’­æ”¾ï¼‰ï¼šå¹¿å‘Šæ›å…‰åäº§ç”Ÿæ’­æ”¾è¡Œä¸ºï¼›
â€¢ Clickï¼ˆç‚¹å‡»ï¼‰ï¼šç‚¹å‡»æ¨å¹¿å†…å®¹æˆ–å¹¿å‘Šï¼›
â€¢ Like or Followï¼ˆç‚¹èµæˆ–å…³æ³¨ï¼‰ï¼šå¯¹æ¨å¹¿æ’­å®¢è¿›è¡Œç‚¹èµæˆ–å…³æ³¨ã€‚

[åŸæ–‡æ®µè½]
For each task \(t \in T\) , we observe a binary label \(y_{t} \in\{0,1\}\) . Given input features \(###\) , the model produces task-specific probabilities \(p_{t}(x)=f_{\theta, t}(x)\) , with shared and task-specific parameters Î¸.
[ä¸­æ–‡ç¿»è¯‘]
å¯¹äºæ¯ä¸ªä»»åŠ¡\(t \in T\)ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°äºŒåˆ†ç±»æ ‡ç­¾\(y_{t} \in\{0,1\}\)ã€‚ç»™å®šè¾“å…¥ç‰¹å¾\(###\)ï¼Œæ¨¡å‹è¾“å‡ºä»»åŠ¡ç‰¹å®šçš„æ¦‚ç‡\(p_{t}(x)=f_{\theta, t}(x)\)ï¼Œå…¶ä¸­Î¸åŒ…å«å…±äº«å‚æ•°å’Œä»»åŠ¡ä¸“ç”¨å‚æ•°ã€‚

[åŸæ–‡æ®µè½]
The unified model (Figure 2C) consists of:
â€¢ a shared encoder \(h_{\phi}(x)\) that maps user, content, context, and creative features into a joint representation \(z=h_{\phi}(x)\) ;
â€¢ task-specific towers \(g_{\psi_{t}}(z)\) that map ğ‘§to logits for each task ğ‘¡.
[ä¸­æ–‡ç¿»è¯‘]
ç»Ÿä¸€æ¨¡å‹ï¼ˆå›¾2Cï¼‰åŒ…æ‹¬ï¼š
â€¢ å…±äº«ç¼–ç å™¨\(h_{\phi}(x)\)ï¼šå°†ç”¨æˆ·ã€å†…å®¹ã€åœºæ™¯å’Œåˆ›æ„ç‰¹å¾æ˜ å°„ä¸ºè”åˆè¡¨ç¤º\(z=h_{\phi}(x)\)ï¼›
â€¢ ä»»åŠ¡ä¸“ç”¨å¡”ç»“æ„\(g_{\psi_{t}}(z)\)ï¼šå°†è”åˆè¡¨ç¤ºğ‘§æ˜ å°„ä¸ºæ¯ä¸ªä»»åŠ¡ğ‘¡çš„å¯¹æ•°å‡ ç‡ï¼ˆlogitsï¼‰ã€‚

[åŸæ–‡æ®µè½]
The predicted probability for task ğ‘¡is 
\[p_{t}(x)=\sigma\left(g_{\psi_{t}}\left(h_{\phi}(x)\right)\right),\]
where \(\sigma(\cdot)\) is the sigmoid function. Architecturally, the shared encoder mirrors the promotions baseline but incorporates ads-specific features and includes both ads and promotions tasks in Ï„ , enabling joint learning over all podcast-related interactions while retaining task-specific capacity.
[ä¸­æ–‡ç¿»è¯‘]
ä»»åŠ¡ğ‘¡çš„é¢„æµ‹æ¦‚ç‡ä¸ºï¼š
\[p_{t}(x)=\sigma\left(g_{\psi_{t}}\left(h_{\phi}(x)\right)\right),\]
å…¶ä¸­\(\sigma(\cdot)\)ä¸ºsigmoidå‡½æ•°ã€‚åœ¨æ¶æ„ä¸Šï¼Œå…±äº«ç¼–ç å™¨ä¸æ¨å¹¿åŸºå‡†æ¨¡å‹ä¸€è‡´ï¼Œä½†æ•´åˆäº†å¹¿å‘Šä¸“ç”¨ç‰¹å¾ï¼Œå¹¶å°†å¹¿å‘Šå’Œæ¨å¹¿ä»»åŠ¡å‡çº³å…¥ä»»åŠ¡é›†åˆÏ„ä¸­ï¼Œä»è€Œèƒ½å¤Ÿåœ¨æ‰€æœ‰æ’­å®¢ç›¸å…³äº¤äº’æ•°æ®ä¸Šè¿›è¡Œè”åˆå­¦ä¹ ï¼ŒåŒæ—¶ä¿ç•™ä»»åŠ¡ä¸“ç”¨çš„å»ºæ¨¡èƒ½åŠ›ã€‚

#### 3.3 Optimization and Loss Balancing
[åŸæ–‡æ®µè½]
We optimize binary cross-entropy losses over all tasks in Ï„ , but with two design choices to control transfer between channels: (1) adaptive loss masking from ads to promotions, and (2) source-balanced sampling between promotions and ads.
[ä¸­æ–‡ç¿»è¯‘]
æˆ‘ä»¬å¯¹Ï„ä¸­çš„æ‰€æœ‰ä»»åŠ¡ä¼˜åŒ–äºŒå…ƒäº¤å‰ç†µæŸå¤±ï¼Œä½†é€šè¿‡ä¸¤é¡¹è®¾è®¡æ¥æ§åˆ¶æ¸ é“é—´çš„çŸ¥è¯†è¿ç§»ï¼š(1) ä»å¹¿å‘Šåˆ°æ¨å¹¿çš„è‡ªé€‚åº”æŸå¤±æ©ç ï¼›(2) æ¨å¹¿å’Œå¹¿å‘Šæ•°æ®çš„æ¥æºå¹³è¡¡é‡‡æ ·ã€‚

[åŸæ–‡æ®µè½]
Let \(T^{P}\) and \(T^{A}\) denote the sets of promotion and ad tasks respectively, with \(T=T^{P} \cup T^{A}\) . We write \(D^{P}\) and \(D^{A}\) for the corresponding sets of promotion and ad impressions, and \(D=D^{P} \cup D^{A}\) Each impression \(x \in D\) has a source label \(s(x) \in\{P, A\}\)
[ä¸­æ–‡ç¿»è¯‘]
è®¾\(T^{P}\)å’Œ\(T^{A}\)åˆ†åˆ«è¡¨ç¤ºæ¨å¹¿ä»»åŠ¡é›†å’Œå¹¿å‘Šä»»åŠ¡é›†ï¼Œæ»¡è¶³\(T=T^{P} \cup T^{A}\)ã€‚\(D^{P}\)å’Œ\(D^{A}\)åˆ†åˆ«è¡¨ç¤ºå¯¹åº”çš„æ¨å¹¿æ›å…‰æ•°æ®é›†å’Œå¹¿å‘Šæ›å…‰æ•°æ®é›†ï¼Œä¸”\(D=D^{P} \cup D^{A}\)ã€‚æ¯ä¸ªæ›å…‰æ ·æœ¬\(x \in D\)éƒ½æœ‰ä¸€ä¸ªæ¥æºæ ‡ç­¾\(s(x) \in\{P, A\}\)ï¼ˆPä»£è¡¨æ¨å¹¿ï¼ŒAä»£è¡¨å¹¿å‘Šï¼‰ã€‚

[åŸæ–‡æ®µè½]
We define a binary mask \(m_{s, t}\) that dictates whether task ğ‘¡should incur loss on an impression from source ğ‘ : 
\[m_{s, t}= \begin{cases}0, & if s=A and t \in \mathcal{T}^{P}, \\ 1, & otherwise. \end{cases}\]
[ä¸­æ–‡ç¿»è¯‘]
æˆ‘ä»¬å®šä¹‰äºŒå…ƒæ©ç \(m_{s, t}\)ï¼Œç”¨äºæŒ‡å®šä»»åŠ¡ğ‘¡æ˜¯å¦éœ€è¦å¯¹æ¥æºä¸ºğ‘ çš„æ›å…‰æ ·æœ¬è®¡ç®—æŸå¤±ï¼š
\[m_{s, t}= \begin{cases}0, & è‹¥s=Aä¸”t \in \mathcal{T}^{P}, \\ 1, & å…¶ä»–æƒ…å†µ. \end{cases}\]

[åŸæ–‡æ®µè½]
This implements directional transfer: promotion impressions update both promotion and ad towers, while ad impressions update only ad towers. The overall training objective is 
\[\mathcal{L}=\sum_{t \in \mathcal{T}} \lambda_{t} \mathbb{E}_{\left(x, y_{t}\right) \sim \mathcal{D}}\left[m_{s(x), t} \ell_{BCE}\left(y_{t}, p_{t}(x)\right)\right],\]
where \(\lambda_{t}\) is a non-negative weight for task ğ‘¡(set to 1 in our deployment) and \(f_{BCE}\) is the binary cross-entropy loss. In practice, the mask prevents ad-specific signals from directly shaping promotion towers, while still allowing promotion signals to aid ads, which is valuable given the relative data sparsity on some ad objectives.
[ä¸­æ–‡ç¿»è¯‘]
è¿™ä¸€è®¾è®¡å®ç°äº†å®šå‘è¿ç§»ï¼šæ¨å¹¿æ›å…‰æ ·æœ¬åŒæ—¶æ›´æ–°æ¨å¹¿å¡”å’Œå¹¿å‘Šå¡”çš„å‚æ•°ï¼Œè€Œå¹¿å‘Šæ›å…‰æ ·æœ¬ä»…æ›´æ–°å¹¿å‘Šå¡”çš„å‚æ•°ã€‚æ•´ä½“è®­ç»ƒç›®æ ‡ä¸ºï¼š
\[\mathcal{L}=\sum_{t \in \mathcal{T}} \lambda_{t} \mathbb{E}_{\left(x, y_{t}\right) \sim \mathcal{D}}\left[m_{s(x), t} \ell_{BCE}\left(y_{t}, p_{t}(x)\right)\right],\]
å…¶ä¸­\(\lambda_{t}\)ä¸ºä»»åŠ¡ğ‘¡çš„éè´Ÿæƒé‡ï¼ˆæˆ‘ä»¬çš„éƒ¨ç½²ä¸­è®¾ä¸º1ï¼‰ï¼Œ\(\ell_{BCE}\)ä¸ºäºŒå…ƒäº¤å‰ç†µæŸå¤±ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¯¥æ©ç å¯é˜²æ­¢å¹¿å‘Šä¸“ç”¨ä¿¡å·ç›´æ¥å½±å“æ¨å¹¿å¡”çš„å‚æ•°å­¦ä¹ ï¼ŒåŒæ—¶ä¿ç•™æ¨å¹¿ä¿¡å·å¯¹å¹¿å‘Šä»»åŠ¡çš„è¾…åŠ©ä½œç”¨â€”â€”è¿™å¯¹äºéƒ¨åˆ†å¹¿å‘Šç›®æ ‡å­˜åœ¨æ•°æ®ç›¸å¯¹ç¨€ç¼ºçš„æƒ…å†µå°¤ä¸ºé‡è¦ã€‚

[åŸæ–‡æ®µè½]
To ensure parity between channels, we use source-balanced sampling: each mini-batch is constructed so that roughly 50% of impressions come from \(D^{P}\) and 50% from \(D^{A}\) . This keeps gradients from promotions and ads at comparable scales and avoids the joint model collapsing toward the higher-volume source.
[ä¸­æ–‡ç¿»è¯‘]
ä¸ºç¡®ä¿ä¸¤ä¸ªæ¸ é“çš„å¹³è¡¡ï¼Œæˆ‘ä»¬é‡‡ç”¨æ¥æºå¹³è¡¡é‡‡æ ·ç­–ç•¥ï¼šæ¯ä¸ªè¿·ä½ æ‰¹æ¬¡ï¼ˆmini-batchï¼‰ä¸­ï¼Œçº¦50%çš„æ›å…‰æ ·æœ¬æ¥è‡ª\(D^{P}\)ï¼Œ50%æ¥è‡ª\(D^{A}\)ã€‚è¿™ä¸€ç­–ç•¥ä½¿æ¨å¹¿å’Œå¹¿å‘Šæ•°æ®äº§ç”Ÿçš„æ¢¯åº¦å¤„äºç›¸è¿‘è§„æ¨¡ï¼Œé¿å…è”åˆæ¨¡å‹å‘æ•°æ®é‡æ›´å¤§çš„æ¥æºå€¾æ–œã€‚

### 4 Experiments and Results
[åŸæ–‡æ®µè½]
We compare the joint model with the promotions-only and ads-only baselines from Section 3.1. We outline the setup, then present offline and online results and summarize ablations.
[ä¸­æ–‡ç¿»è¯‘]
æˆ‘ä»¬å°†è”åˆæ¨¡å‹ä¸3.1èŠ‚ä¸­çš„ä»…æ¨å¹¿åŸºå‡†æ¨¡å‹å’Œä»…å¹¿å‘ŠåŸºå‡†æ¨¡å‹è¿›è¡Œå¯¹æ¯”ã€‚æœ¬èŠ‚é¦–å…ˆæ¦‚è¿°å®éªŒè®¾ç½®ï¼Œç„¶åå‘ˆç°ç¦»çº¿å’Œåœ¨çº¿å®éªŒç»“æœï¼Œå¹¶æ€»ç»“æ¶ˆèåˆ†æç»“è®ºã€‚

#### 4.1 Experimental Setup
[åŸæ–‡æ®µè½]
Data and splits. We train on production logs from Spotifyâ€™s podcast ads and promotions systems over a multi-month period. Impressions are temporally split into training, validation, and test sets: earlier days for training, intermediate days for validation, and the most recent days for testing. Ads and promotions impressions are pooled but retain channel labels and task-specific outcomes.
[ä¸­æ–‡ç¿»è¯‘]
æ•°æ®ä¸åˆ’åˆ†ã€‚æˆ‘ä»¬ä½¿ç”¨Spotifyæ’­å®¢å¹¿å‘Šå’Œæ¨å¹¿ç³»ç»Ÿçš„æ•°æœˆç”Ÿäº§æ—¥å¿—è¿›è¡Œè®­ç»ƒã€‚æ›å…‰æ•°æ®æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼šæ—©æœŸæ•°æ®ç”¨äºè®­ç»ƒï¼Œä¸­æœŸæ•°æ®ç”¨äºéªŒè¯ï¼Œæœ€æ–°æ•°æ®ç”¨äºæµ‹è¯•ã€‚å¹¿å‘Šå’Œæ¨å¹¿æ›å…‰æ•°æ®è¢«åˆå¹¶ä½¿ç”¨ï¼Œä½†ä¿ç•™äº†æ¸ é“æ ‡ç­¾å’Œä»»åŠ¡ç‰¹å®šç»“æœæ ‡ç­¾ã€‚

[åŸæ–‡æ®µè½]
Evaluation metrics. Offline, we use Average Precision (AP), which summarizes the precisionâ€“recall curve and is more informative than AUC-ROC under heavy class imbalance. Online, we focus on:
Effective Cost-Per-Stream (eCPS): ad spend divided by resulting podcast streams;
â€¢ Stream rate (i2s): impression-to-stream rate;
â€¢ Click-through rate (CTR).
Metrics are reported for all podcasts and for less-streamed creators (shows with fewer than 5,000 streams), a segment strongly affected by cold-start.
[ä¸­æ–‡ç¿»è¯‘]
è¯„ä¼°æŒ‡æ ‡ã€‚ç¦»çº¿è¯„ä¼°é‡‡ç”¨å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰ï¼Œè¯¥æŒ‡æ ‡å¯æ¦‚æ‹¬ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ï¼Œåœ¨ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡åœºæ™¯ä¸‹æ¯”AUC-ROCæ›´å…·ä¿¡æ¯é‡ã€‚åœ¨çº¿è¯„ä¼°é‡ç‚¹å…³æ³¨ä»¥ä¸‹æŒ‡æ ‡ï¼š
â€¢ æœ‰æ•ˆæ¯æ’­æ”¾æˆæœ¬ï¼ˆeCPSï¼‰ï¼šå¹¿å‘Šæ”¯å‡ºé™¤ä»¥äº§ç”Ÿçš„æ’­å®¢æ’­æ”¾é‡ï¼›
â€¢ æ’­æ”¾ç‡ï¼ˆi2sï¼‰ï¼šæ›å…‰-æ’­æ”¾è½¬åŒ–ç‡ï¼›
â€¢ ç‚¹å‡»ç‡ï¼ˆCTRï¼‰ï¼šç‚¹å‡»é‡ä¸æ›å…‰é‡çš„æ¯”å€¼ã€‚
è¯„ä¼°ç»“æœåˆ†åˆ«é’ˆå¯¹æ‰€æœ‰æ’­å®¢å’Œä½æ’­æ”¾é‡åˆ›ä½œè€…ï¼ˆæ’­æ”¾é‡å°‘äº5000æ¬¡çš„èŠ‚ç›®ï¼‰æŠ¥å‘Šâ€”â€”åè€…æ˜¯å—å†·å¯åŠ¨é—®é¢˜å½±å“æœ€ä¸¥é‡çš„ç¾¤ä½“ã€‚

[åŸæ–‡æ®µè½]
Training details. All models share the same optimizer (Adam) and learning-rate schedule. Hyperparameters are tuned using validation AP on stream tasks.
[ä¸­æ–‡ç¿»è¯‘]
è®­ç»ƒç»†èŠ‚ã€‚æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„ä¼˜åŒ–å™¨ï¼ˆAdamï¼‰å’Œå­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ã€‚è¶…å‚æ•°é€šè¿‡æ’­æ”¾ä»»åŠ¡çš„éªŒè¯é›†å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰è¿›è¡Œè°ƒä¼˜ã€‚

#### 4.2 Offline Evaluation Results
[åŸæ–‡æ®µè½]
Table 1 compares the multi-objective promoâ€“ads model with the production baseline and alternative task groupings. The unified â€œPromo + Ads 5-task MTLâ€ model provides the strongest performance.
[ä¸­æ–‡ç¿»è¯‘]
è¡¨1å¯¹æ¯”äº†å¤šç›®æ ‡æ¨å¹¿-å¹¿å‘Šè”åˆæ¨¡å‹ä¸ç”Ÿäº§ç¯å¢ƒåŸºå‡†æ¨¡å‹åŠå…¶ä»–ä»»åŠ¡åˆ†ç»„æ–¹æ¡ˆçš„æ€§èƒ½ã€‚ç»“æœæ˜¾ç¤ºï¼Œç»Ÿä¸€çš„â€œæ¨å¹¿+å¹¿å‘Š5ä»»åŠ¡å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰â€æ¨¡å‹è¡¨ç°æœ€ä¼˜ã€‚

[åŸæ–‡è¡¨æ ¼æ ‡é¢˜]
Table 1: Average Precision (AP) comparison across configurations. Relative change to the baseline promotions model (Figure 2A).
[ä¸­æ–‡ç¿»è¯‘]
è¡¨1ï¼šä¸åŒé…ç½®çš„å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰å¯¹æ¯”ã€‚ç»“æœä¸ºç›¸å¯¹äºåŸºå‡†æ¨å¹¿æ¨¡å‹ï¼ˆå›¾2Aï¼‰çš„ç›¸å¯¹å˜åŒ–ç‡ã€‚

[åŸæ–‡è¡¨æ ¼å†…å®¹]
| Task Setup | Promotions AP | Ads AP |
| --- | --- | --- |
| Promo Stream head-only | âˆ’ 7 . 9% | âˆ’ 8 . 8% |
| Ads Stream head-only | âˆ’ 65 . 2% | + 27 . 0% |
| Ads Stream + ANC heads | âˆ’ 64 . 8% | + 46 . 5% |
| Promo + Ads 5-task MTL | + 4 . 5% | + 50 . 2% |
[ä¸­æ–‡ç¿»è¯‘]
| ä»»åŠ¡é…ç½® | æ¨å¹¿ä»»åŠ¡å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰ | å¹¿å‘Šä»»åŠ¡å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰ |
| --- | --- | --- |
| ä»…æ¨å¹¿æ’­æ”¾å¤´ | âˆ’7.9% | âˆ’8.8% |
| ä»…å¹¿å‘Šæ’­æ”¾å¤´ | âˆ’65.2% | +27.0% |
| å¹¿å‘Šæ’­æ”¾å¤´+è¾…åŠ©ä»»åŠ¡å¤´ | âˆ’64.8% | +46.5% |
| æ¨å¹¿+å¹¿å‘Š5ä»»åŠ¡å¤šä»»åŠ¡å­¦ä¹  | +4.5% | +50.2% |

[åŸæ–‡æ®µè½]
Relative to the promotions-only baseline, the joint model improves Promotions AP by +4.5% and Ads AP by +50.2%. Ads-only configurations, even with ancillary heads, remain much weaker on promotions and still fall short of the joint model on ads, indicating that cross-channel transfer between promotions and ads is critical.
[ä¸­æ–‡ç¿»è¯‘]
ç›¸è¾ƒäºä»…æ¨å¹¿åŸºå‡†æ¨¡å‹ï¼Œè”åˆæ¨¡å‹çš„æ¨å¹¿ä»»åŠ¡å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰æå‡4.5%ï¼Œå¹¿å‘Šä»»åŠ¡å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰æå‡50.2%ã€‚ä»…å¹¿å‘Šé…ç½®ï¼ˆå³ä½¿åŒ…å«è¾…åŠ©ä»»åŠ¡å¤´ï¼‰åœ¨æ¨å¹¿ä»»åŠ¡ä¸Šçš„è¡¨ç°ä»æ˜¾è‘—è¾ƒå¼±ï¼Œä¸”åœ¨å¹¿å‘Šä»»åŠ¡ä¸Šä¹Ÿä¸åŠè”åˆæ¨¡å‹ï¼Œè¿™è¡¨æ˜å¹¿å‘Šä¸æ¨å¹¿ä¹‹é—´çš„è·¨æ¸ é“çŸ¥è¯†è¿ç§»è‡³å…³é‡è¦ã€‚

#### 4.3 Effect of Ancillary Heads
[åŸæ–‡æ®µè½]
The joint model includes ancillary heads for clicks, likes, and follows (ANC). Table 1 shows that adding ANC heads to the ads-only model increases Ads AP from +27% to +46.5% relative to baseline, confirming that modeling intermediate engagement signals benefits stream prediction. However, this ads-only configuration severely degrades Promotions AP (around âˆ’65%), indicating that ancillary heads alone are insufficient without promotions data.
[ä¸­æ–‡ç¿»è¯‘]
è”åˆæ¨¡å‹åŒ…å«ç‚¹å‡»ã€ç‚¹èµå’Œå…³æ³¨ç­‰è¾…åŠ©ä»»åŠ¡å¤´ï¼ˆANCï¼‰ã€‚è¡¨1æ˜¾ç¤ºï¼Œåœ¨ä»…å¹¿å‘Šæ¨¡å‹ä¸­æ·»åŠ è¾…åŠ©ä»»åŠ¡å¤´åï¼Œå¹¿å‘Šä»»åŠ¡å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰ç›¸å¯¹äºåŸºå‡†æ¨¡å‹ä»+27%æå‡è‡³+46.5%ï¼Œè¿™è¯å®äº†å»ºæ¨¡ä¸­é—´å‚ä¸ä¿¡å·å¯¹æ’­æ”¾é‡é¢„æµ‹çš„ç§¯æä½œç”¨ã€‚ç„¶è€Œï¼Œè¿™ç§ä»…å¹¿å‘Šé…ç½®ä¼šå¯¼è‡´æ¨å¹¿ä»»åŠ¡å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰å¤§å¹…ä¸‹é™ï¼ˆçº¦âˆ’65%ï¼‰ï¼Œè¡¨æ˜ä»…ä¾é è¾…åŠ©ä»»åŠ¡å¤´è€Œç¼ºä¹æ¨å¹¿æ•°æ®æ˜¯ä¸å¤Ÿçš„ã€‚

[åŸæ–‡æ®µè½]
In the unified MTL setting, ANC heads over both ads and promotions improve AP for both channels. Ancillary labels are most useful when combined with cross-channel training, allowing the shared encoder to learn richer user and content representations.
[ä¸­æ–‡ç¿»è¯‘]
åœ¨ç»Ÿä¸€çš„å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰åœºæ™¯ä¸­ï¼ŒåŒæ—¶è¦†ç›–å¹¿å‘Šå’Œæ¨å¹¿çš„è¾…åŠ©ä»»åŠ¡å¤´å¯æå‡ä¸¤ä¸ªæ¸ é“çš„å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰ã€‚è¾…åŠ©æ ‡ç­¾åœ¨ä¸è·¨æ¸ é“è®­ç»ƒç»“åˆæ—¶å‘æŒ¥æœ€å¤§ä½œç”¨ï¼Œä½¿å…±äº«ç¼–ç å™¨èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´ä¸°å¯Œçš„ç”¨æˆ·å’Œå†…å®¹è¡¨ç¤ºã€‚

#### 4.4 Online A/B Test Results
[åŸæ–‡æ®µè½]
We ran a budget-split A/B test across 180+ markets, comparing the 5-task joint model with the baseline that uses the promotions model for ad cold-start (Figure 2A).
[ä¸­æ–‡ç¿»è¯‘]
æˆ‘ä»¬åœ¨180å¤šä¸ªå¸‚åœºå¼€å±•äº†é¢„ç®—æ‹†åˆ†A/Bæµ‹è¯•ï¼Œå°†5ä»»åŠ¡è”åˆæ¨¡å‹ä¸ä½¿ç”¨æ¨å¹¿æ¨¡å‹è¿›è¡Œå¹¿å‘Šå†·å¯åŠ¨çš„åŸºå‡†æ¨¡å‹ï¼ˆå›¾2Aï¼‰è¿›è¡Œå¯¹æ¯”ã€‚

[åŸæ–‡æ®µè½]
The joint model improves impression-to-stream rate, click-through rate, and cost-efficiency simultaneously. Gains are largest for less-streamed creators, with a 22% eCPS reduction and 27% more streams, proving this approach particularly effective for cold-start content.
[ä¸­æ–‡ç¿»è¯‘]
è”åˆæ¨¡å‹åŒæ—¶æå‡äº†æ›å…‰-æ’­æ”¾è½¬åŒ–ç‡ã€ç‚¹å‡»ç‡å’Œæˆæœ¬æ•ˆç›Šã€‚ä½æ’­æ”¾é‡åˆ›ä½œè€…çš„æ”¶ç›Šæœ€ä¸ºæ˜¾è‘—ï¼šæœ‰æ•ˆæ¯æ’­æ”¾æˆæœ¬ï¼ˆeCPSï¼‰é™ä½22%ï¼Œæ’­æ”¾é‡å¢åŠ 27%ï¼Œè¿™è¯æ˜è¯¥æ–¹æ³•å¯¹å†·å¯åŠ¨å†…å®¹å°¤ä¸ºæœ‰æ•ˆã€‚

##### 4.4.1 Cold-Start Performance
[åŸæ–‡æ®µè½]
To better understand how the joint model behaves across podcasts of different popularity levels, we further segment results by Spotifyâ€™s stream tiers. Podcasts are grouped into eight tiers based on the number of listening hours (longer than 60 seconds) accumulated over a rolling 30-day window. For our purposes, Tiers 0â€“2 correspond to high-stream podcasts, while Tiers 3â€“5 capture low-stream shows, aligned with less-streamed creator segment.
[ä¸­æ–‡ç¿»è¯‘]
ä¸ºäº†æ›´æ·±å…¥äº†è§£è”åˆæ¨¡å‹åœ¨ä¸åŒçƒ­åº¦æ’­å®¢ä¸­çš„è¡¨ç°ï¼Œæˆ‘ä»¬æ ¹æ®Spotifyçš„æ’­æ”¾é‡ç­‰çº§å¯¹ç»“æœè¿›è¡Œè¿›ä¸€æ­¥ç»†åˆ†ã€‚æ’­å®¢æ ¹æ®è¿‡å»30å¤©çš„ç´¯è®¡æ”¶å¬æ—¶é•¿ï¼ˆè¶…è¿‡60ç§’ï¼‰åˆ†ä¸º8ä¸ªç­‰çº§ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œ0-2çº§å¯¹åº”é«˜æ’­æ”¾é‡æ’­å®¢ï¼Œ3-5çº§å¯¹åº”ä½æ’­æ”¾é‡èŠ‚ç›®ï¼Œä¸ä½æ’­æ”¾é‡åˆ›ä½œè€…ç¾¤ä½“ä¸€è‡´ã€‚

[åŸæ–‡æ®µè½]
When we re-evaluate the A/B test by tiers, we observe markedly large improvements for lower-streamed podcasts. For high-stream tiers, the relative improvement in i2s grows from approximately +7% (Tier 0) to +20% (Tier 2), while mean CPS decreases by 4â€“17%. In contrast, low-stream tiers see substantially larger effects: i2s improves by roughly +27% (Tier 3), +33% (Tier 4), and up to +60% for Tier 5, with corresponding CPS reductions of about 20%, 24%, and 38%, respectively. This monotonic pattern-larger relative gains as we move from Tier 0 to Tier 5-provides strong evidence that the unified model is particularly effective in cold-start and low-stream regimes, where data is sparse and traditional siloed models struggle.
[ä¸­æ–‡ç¿»è¯‘]
æŒ‰ç­‰çº§é‡æ–°è¯„ä¼°A/Bæµ‹è¯•ç»“æœåï¼Œæˆ‘ä»¬å‘ç°ä½æ’­æ”¾é‡æ’­å®¢çš„æå‡æ•ˆæœå°¤ä¸ºæ˜¾è‘—ã€‚å¯¹äºé«˜æ’­æ”¾é‡ç­‰çº§ï¼Œæ›å…‰-æ’­æ”¾è½¬åŒ–ç‡ï¼ˆi2sï¼‰çš„ç›¸å¯¹æå‡ä»çº¦+7%ï¼ˆ0çº§ï¼‰å¢é•¿è‡³+20%ï¼ˆ2çº§ï¼‰ï¼Œå¹³å‡æ¯æ’­æ”¾æˆæœ¬ï¼ˆCPSï¼‰é™ä½4%-17%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä½æ’­æ”¾é‡ç­‰çº§çš„æå‡æ•ˆæœæ›´ä¸ºçªå‡ºï¼š3çº§çš„æ›å…‰-æ’­æ”¾è½¬åŒ–ç‡ï¼ˆi2sï¼‰æå‡çº¦+27%ï¼Œ4çº§æå‡+33%ï¼Œ5çº§æœ€é«˜æå‡+60%ï¼›å¯¹åº”çš„å¹³å‡æ¯æ’­æ”¾æˆæœ¬ï¼ˆCPSï¼‰åˆ†åˆ«é™ä½çº¦20%ã€24%å’Œ38%ã€‚è¿™ç§ä»0çº§åˆ°5çº§ç›¸å¯¹æ”¶ç›Šé€æ­¥å¢å¤§çš„å•è°ƒæ¨¡å¼ï¼Œæœ‰åŠ›åœ°è¯æ˜äº†ç»Ÿä¸€æ¨¡å‹åœ¨å†·å¯åŠ¨å’Œä½æ’­æ”¾é‡åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§â€”â€”è¿™äº›åœºæ™¯ä¸­æ•°æ®ç¨€ç¼ºï¼Œä¼ ç»Ÿçš„ç‹¬ç«‹æ¨¡å‹å¾€å¾€è¡¨ç°ä¸ä½³ã€‚

### 5 Conclusion
[åŸæ–‡æ®µè½]
This paper presents the successful development and deployment of a unified multi-task model for podcast ad and promotion targeting at Spotify. Our joint optimization approach markedly improves upon traditional siloed models by effectively leveraging transfer learning; pre-training on extensive advertising data enables strong performance across diverse tasks, including promotions, particularly in cold-start scenarios.
[ä¸­æ–‡ç¿»è¯‘]
æœ¬æ–‡ä»‹ç»äº†SpotifyæˆåŠŸå¼€å‘å¹¶éƒ¨ç½²çš„æ’­å®¢å¹¿å‘Šä¸æ¨å¹¿å®šå‘ç»Ÿä¸€å¤šä»»åŠ¡æ¨¡å‹ã€‚æˆ‘ä»¬çš„è”åˆä¼˜åŒ–æ–¹æ³•é€šè¿‡æœ‰æ•ˆåˆ©ç”¨è¿ç§»å­¦ä¹ ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ç‹¬ç«‹æ¨¡å‹ï¼›åŸºäºå¤§è§„æ¨¡å¹¿å‘Šæ•°æ®çš„é¢„è®­ç»ƒä½¿æ¨¡å‹åœ¨åŒ…æ‹¬æ¨å¹¿åœ¨å†…çš„å¤šç§ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨å†·å¯åŠ¨åœºæ™¯ä¸‹æ•ˆæœæ˜¾è‘—ã€‚

[åŸæ–‡æ®µè½]
Key lessons from this initiative highlight the power of unifying disparate yet related recommendation tasks, which not only unlocks significant performance gains but also fosters crucial organizational synergies, such as improved cross-team collaboration and strategic alignment by breaking down previously siloed efforts. Furthermore, leveraging transfer learning within such a joint model effectively mitigates cold-start issues for new content and objectives. The modelâ€™s capacity to simultaneously enhance diverse business objectives-spanning ad streams, ad clicks, and promotional streams-with substantial gains suggests operation nearer to a Pareto optimal frontier [11]. While our study focuses on podcasts, the approach naturally extends to other verticals (e.g., music, audiobooks, video) where ads and organic promotions share user and content representations.
[ä¸­æ–‡ç¿»è¯‘]
è¯¥é¡¹ç›®å¸¦æ¥çš„å…³é”®ç»éªŒè¡¨æ˜ï¼Œæ•´åˆä¸åŒä½†ç›¸å…³çš„æ¨èä»»åŠ¡å…·æœ‰å·¨å¤§ä»·å€¼â€”â€”è¿™ä¸ä»…èƒ½å¸¦æ¥æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¿˜èƒ½ä¿ƒè¿›é‡è¦çš„ç»„ç»‡ååŒæ•ˆåº”ï¼Œä¾‹å¦‚é€šè¿‡æ‰“ç ´ä»¥å¾€ç‹¬ç«‹çš„å·¥ä½œæ¨¡å¼ï¼Œæ”¹å–„è·¨å›¢é˜Ÿåä½œå’Œæˆ˜ç•¥ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œåœ¨è¿™ç§è”åˆæ¨¡å‹ä¸­åˆ©ç”¨è¿ç§»å­¦ä¹ ï¼Œå¯æœ‰æ•ˆç¼“è§£æ–°å†…å®¹å’Œæ–°ç›®æ ‡çš„å†·å¯åŠ¨é—®é¢˜ã€‚è¯¥æ¨¡å‹èƒ½å¤ŸåŒæ—¶æå‡åŒ…æ‹¬å¹¿å‘Šæ’­æ”¾é‡ã€å¹¿å‘Šç‚¹å‡»é‡å’Œæ¨å¹¿æ’­æ”¾é‡åœ¨å†…çš„å¤šç§ä¸šåŠ¡ç›®æ ‡ï¼Œä¸”å‡å–å¾—äº†æ˜¾è‘—æ”¶ç›Šï¼Œè¿™è¡¨æ˜å…¶è¿è¡ŒçŠ¶æ€æ›´æ¥è¿‘å¸•ç´¯æ‰˜æœ€ä¼˜å‰æ²¿[11]ã€‚å°½ç®¡æœ¬ç ”ç©¶èšç„¦äºæ’­å®¢é¢†åŸŸï¼Œä½†è¯¥æ–¹æ³•å¯è‡ªç„¶æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼ˆå¦‚éŸ³ä¹ã€æœ‰å£°ä¹¦ã€è§†é¢‘ï¼‰â€”â€”è¿™äº›é¢†åŸŸä¸­ï¼Œå¹¿å‘Šå’Œè‡ªç„¶æ¨å¹¿å…±äº«ç”¨æˆ·å’Œå†…å®¹è¡¨ç¤ºï¼Œå…·å¤‡è”åˆå»ºæ¨¡çš„åŸºç¡€ã€‚

[åŸæ–‡è¡¨æ ¼æ ‡é¢˜]
Table 2: A/B test results for all and less-streamed podcast creators \((p-value <0.05)\) ). Less-streamed podcasts have fewer than 5,000 streams. Relative change to the baseline (Figure 2A).
[ä¸­æ–‡ç¿»è¯‘]
è¡¨2ï¼šæ‰€æœ‰æ’­å®¢ä¸ä½æ’­æ”¾é‡æ’­å®¢åˆ›ä½œè€…çš„A/Bæµ‹è¯•ç»“æœï¼ˆ\(på€¼<0.05\)ï¼‰ã€‚ä½æ’­æ”¾é‡æ’­å®¢æŒ‡æ’­æ”¾é‡å°‘äº5000æ¬¡çš„èŠ‚ç›®ã€‚ç»“æœä¸ºç›¸å¯¹äºåŸºå‡†æ¨¡å‹ï¼ˆå›¾2Aï¼‰çš„ç›¸å¯¹å˜åŒ–ç‡ã€‚

[åŸæ–‡è¡¨æ ¼å†…å®¹]

| Segment | i2s | eCPS | CTR | # streams |
| --- | --- | --- | --- | --- |
| Less-streamed creators | +24% | âˆ’22% | +10% | +27% |
| All podcasts | +18% | âˆ’20% | +9% | +18% |

[ä¸­æ–‡ç¿»è¯‘]

| ç¾¤ä½“ | æ›å…‰-æ’­æ”¾è½¬åŒ–ç‡ï¼ˆi2sï¼‰ | æœ‰æ•ˆæ¯æ’­æ”¾æˆæœ¬ï¼ˆeCPSï¼‰ | ç‚¹å‡»ç‡ï¼ˆCTRï¼‰ | æ’­æ”¾é‡ï¼ˆ# streamsï¼‰ |
| --- | --- | --- | --- | --- |
| ä½æ’­æ”¾é‡åˆ›ä½œè€… | +24% | âˆ’22% | +10% | +27% |
| æ‰€æœ‰æ’­å®¢ | +18% | âˆ’20% | +9% | +18% |